<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: MongoDB | The Disco Blog]]></title>
  <link href="http://aglover.github.com/blog/categories/mongodb/atom.xml" rel="self"/>
  <link href="http://aglover.github.com/"/>
  <updated>2012-12-21T21:59:55-05:00</updated>
  <id>http://aglover.github.com/</id>
  <author>
    <name><![CDATA[Andrew Glover]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Pushing Mongo GridFS files with Sinatra]]></title>
    <link href="http://aglover.github.com/blog/2012/12/21/pushing-mongo-gridfs-files-with-sinatra/"/>
    <updated>2012-12-21T21:19:00-05:00</updated>
    <id>http://aglover.github.com/blog/2012/12/21/pushing-mongo-gridfs-files-with-sinatra</id>
    <content type="html"><![CDATA[<p><a href="http://www.app47.com/">We</a> recently implemented a new feature that required two interesting aspects: storing a file in <a href="http://www.mongodb.org/">MongoDB</a> using <a href="http://docs.mongodb.org/manual/applications/gridfs/">GridFS</a> (think traditional <a href="http://en.wikipedia.org/wiki/Binary_large_object">Blob</a>) and then pushing that file down to a browser. Along the way, I discovered a lot of questions on <a href="http://stackoverflow.com/">stackoverflow</a> and the like pertaining to various aspects of GridFS and <a href="http://www.sinatrarb.com/">Sinatra</a> pushes, so I thought I'd explain what we did.</p>

<p>First off, GridFS is a specification for storing and retrieving large documents. In essence, Mongo breaks a large document into smaller documents (called <em>chunks</em>) and stores them in one collection and associates the meta data related to the aggregated chunks into another collection. It's a fairly handy feature and in our case, it made sense to use <a href="http://docs.mongodb.org/manual/faq/developers/#faq-developers-when-to-use-gridfs">GridFS</a> rather than <a href="http://aws.amazon.com/s3/">S3</a> (or the underlying file system).</p>

<p>All MongoDB drivers implement a similar access pattern to leverage GridFS and they hide the complexity of working with chunks. For example, <a href="https://github.com/mongodb/mongo-ruby-driver">the Ruby driver</a> simply provides a <a href="https://github.com/mongodb/mongo-ruby-driver/wiki/GridFS">single interface to manage the two GridFS collections</a>. In fact, <a href="https://github.com/mongodb/mongo-ruby-driver/blob/master/lib/mongo/gridfs/grid.rb">the interface</a> basically provides two methods: <code>get</code> &amp; <code>put</code> which might seem somewhat limiting, especially because <code>get</code> takes an <code>_id</code>! What's more, you can add rich meta data to a GridFS document (via the <code>put</code> call) -- data you'd conceivably want to query by, but at first glance, you can't via the <code>get</code> method. Nevertheless, because GridFS is ultimately two collections in Mongo, you can query them as you would any other collection.</p>

<p>Thus, finding files by some attribute other than their <code>_id</code> is as easy as writing the corresponding query:</p>

<p><code>ruby GridFS example
file = @mongo['user_apks.files'].find({:filename =&gt; user_id.to_s}).first
</code></p>

<p>Keep in mind, however, that the result returned above is a JSON document -- i.e. the variable <code>file</code> above isn't a pointer to an actual I/O instance but simply a JSON document with its details. To get the actual file, use the <code>get</code> method provided by the driver's GridFS facade -- this'll handle the details of grabbing the file from GridFS. The <code>get</code> method takes an <code>_id</code>, which you can get from the <code>file</code> document. Thus, to get an instance of a readable file, you can grab it like so:</p>

<p><code>ruby get via _id
@grid.get(file['_id'])
</code></p>

<p>Thus, with the <code>get</code> call you can actually get ahold of a file instance and not some JSON document describing it.</p>

<p>To push this instance down to a browser using <a href="http://thediscoblog.com/blog/2012/12/10/sinatra-coffeescript-and-haml-swinging-in-4-steps/">Sinatra</a>, you need to do 3 things:</p>

<ul>
<li>set the content type</li>
<li>set the attachment name</li>
<li>write the file to the response</li>
</ul>


<p>In our case, the file is an <a href="http://developer.android.com/index.html">Android</a> app; accordingly, the content type is <code>application/vnd.android.package-archive</code> and as you'll note, the attachment is simply the name of the <code>.apk</code> file. Finally, the response to the request is written to by <em>reading</em> from the corresponding GridFS file:</p>

<p><code>ruby Sinatra push
get '/some/url/:account_id/:user_id', :agent =&gt; /Android/ do |account_id, user_id|
  file = # get the file from GridFS
  content_type 'application/vnd.android.package-archive'
  attachment "#{file.filename}.apk"
  response.write file.read
end
</code>
As you can see, it's all quite easy -- GridFS is simply a facade in front of two collections; moreover, forcing a download in Sinatra is three straightforward steps.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[MongoDB from the trenches: prudent production planning]]></title>
    <link href="http://aglover.github.com/blog/2012/09/11/mongodb-from-the-trenches-prudent-production-planning/"/>
    <updated>2012-09-11T11:34:00-04:00</updated>
    <id>http://aglover.github.com/blog/2012/09/11/mongodb-from-the-trenches-prudent-production-planning</id>
    <content type="html"><![CDATA[<p><img class="left" src="/images/mine/mongodb_icon.png">While starting out with <a href="http://http://www.Mongodb.org/">MongoDB</a> is super easy, there are few things you should keep in mind as you move from a development environment into a production one. No one wants to get paged at 3am because a customer can’t complete an order on your awesome e-commerce site because your database isn’t responding fast enough or worse, is down.</p>

<p>Planning for a production deployment with MongoDB <a href="http://www.mongodb.org/display/DOCS/Production+Notes">isn't rocket science</a>, but I must warn you, it'll cost money, especially if your application actually gets used <em>a lot</em>, which is every developer's dream. Therefore, like all databases, you need to plan for high availability and you’ll want the maximum performance benefits you can get for your money in a production environment.</p>

<p>First and foremost, <a href="http://www.mongodb.org/display/DOCS/Caching">Mongo likes memory</a>; that is, frequently accessed data is stored directly in memory; moreover, writes are also stored in memory until being flushed to disk. It’s imperative that you provide enough memory for Mongo to store a valid working dataset; otherwise, Mongo will have to go to the disk to retrieve, what should be, fast lookups via indexed data. This is sloooooow. Therefore, a good rule of thumb is to plan to run your Mongo instances with <em>as much memory as you can afford</em>.</p>

<p>You can get an idea for your working data set by running <code>Mongostat</code> -- this is a handy command line utility that’ll give you a second-by-second view into what Mongo is up to -- one particular metric you’ll see is resident memory (labeled as <code>res</code>) -- this will give you a good idea of how much memory Mongo’s using at any given moment. If this number exceeds what you have available on a given machine, then Mongo is having to go to disk, which is going to be a lot slower.</p>

<p>Not all data can be stored in memory; every document in Mongo is eventually written to disk. And like always, I/O is always a slow operation compared to working with memory. This is why, for example, writes in Mongo can be so fast -- drivers allow you to, essentially, fire and forget and the actual write to disk is done later, asynchronously. Reads can also incur an I/O penalty when something requested isn’t in working memory.</p>

<p>Thus, for high performance reads and writes, <em>pay attention to the underlying disks</em>. A key metric here is IOPS or input/output operations per second. Mongo will be extremely happy, for example, <a href="http://www.mongodb.org/display/DOCS/SSD">in an SSD environment</a>, provided you can afford it. <a href="http://en.wikipedia.org/wiki/IOPS">Just take a look at various IOPS comparisons between SSDs and traditional spinning disks</a> -- super fast RPM disks can achieve IOPS in the 200 range. Typical SSD drives are attaining wild numbers, orders of magnitude higher (like in the 100’s of thousands of IOPS). It’s crazy how fast SSDs are compared to traditional hard drives.</p>

<p>RAM is still faster than SSDs, so you’ll still want to understand your working set of data and ensure you have plenty of memory to contain it.</p>

<p>Finally, for maximum availably, <em>you really should be using Mongo’s <a href="http://www.mongodb.org/display/DOCS/Replica+Sets">replica sets</a></em>. Setting up a cluster of Mongo instances is so incredibility easy that there really isn’t a good reason not to do it. The benefits of doing so are manifold, including:</p>

<ul>
<li>data redundancy</li>
<li>high availability via automated failover</li>
<li>disaster recovery</li>
</ul>


<p>Plus, running a replica set makes maintenance so much easier as you can bring nodes off line and on line w/out an interruption of service. And you can run nodes in a replica set on commodity hardware (don’t forget about my points regarding memory and I/O though).</p>

<p>Accordingly, when looking to move Mongo into a production environment, you need to consider memory, I/O performance, and replica sets. Running a high performant, high availability replica set'ed Mongo, not surprisingly, will cost you. If you're looking for options for running Mongo in a production environment, I can't recommend enough the team at <a href="https://mongohq.com/">MongoHQ</a>.</p>

<p>I'm a huge fan of Mongo. Check out some of the articles, videos, and podcasts that I've done, which focus on Mongo, including:</p>

<ul>
<li><a href="http://www.ibm.com/developerworks/java/library/j-javadev2-12/">Java development 2.0: MongoDB: A NoSQL datastore with (all the right) RDBMS moves</a></li>
<li><a href="http://public.dhe.ibm.com/software/dw/demos/jmongodb/index.html">Video demo: An introduction to MongoDB</a></li>
<li><a href="http://www.ibm.com/developerworks/java/library/j-gloverpodcast/#Horowitz">Eliot Horowitz on MongoDB</a></li>
<li><a href="http://www.ibm.com/developerworks/java/library/j-gloverpodcast4/index.html#francia">10gen's Steve Francia talks MongoDB</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[MongoDB from the trenches: masochistic embedded collections]]></title>
    <link href="http://aglover.github.com/blog/2012/09/03/mongodb-from-the-trenches-masochistic-embedded-collections/"/>
    <updated>2012-09-03T21:47:00-04:00</updated>
    <id>http://aglover.github.com/blog/2012/09/03/mongodb-from-the-trenches-masochistic-embedded-collections</id>
    <content type="html"><![CDATA[<p><a href="http://www.mongodb.org/">MongoDB</a> supports rich documents that can include, among other things, embedded documents. This feature embodies a <em>has-a</em> relationship quite nicely and can, if modeled properly, reduce the number of finds required to ascertain certain data as there are no joins in Mongo.</p>

<p>As classic example of embedding a collection of documents inside a parent document is contact addresses (i.e. mailing, email, twitter, etc) associated with a person. Think business cards. You can, of course, model this in any number of ways -- in the traditional relational world, this would be a one-to-many relationship between at least two tables. Nevertheless, with a document-oriented database, you can model a parent <code>person</code> document with an embedded collection of <code>contacts</code> that are each themselves documents containing, say, <em>type</em> (i.e. phone, twitter, email) and <em>value</em> (which could be 555-555-555, @jon_doe, etc).</p>

<p>This relationship with Mongo works nicely <em>if the child embedded document never needs to exist outside of its parent</em>. In the case of a business card, the contact document representing a phone number, for example, doesn't necessarily make sense outside the context of the person who it belongs to. With this relationship, you can easily find a particular person via his/her phone number (that is, via Mongo's query language, you can reach inside arrays via its <a href="http://www.mongodb.org/display/DOCS/Dot+Notation+(Reaching+into+Objects">dot notion</a>) effortlessly). And, once you have a handle to a person, you don't need to execute a series of finds to ascertain contact information -- it's all right there.</p>

<p>Nevertheless, things start to get painful quickly if you'd like to operate solely on a singular embedded document. That is, if you execute finds that are intended to deal with the expected resultant embedded document, you're in for some work: as of Mongo 2.2, you can't select a singular document from within a collection residing in a parent via a query. A find in this case will pull <em>everything</em> -- it's up to you (i.e your application) to filter things.</p>

<p>An example will probably help: imagine the business card example from earlier -- a <code>person</code> document containing an embedded collection of <code>contacts</code>:</p>

<p>``` javascript person document
{</p>

<pre><code>first_name: 'Andrew',
last_name: 'Glover',
contacts: [ 
{
  type: 'cell',
  value: '555-555-5555',
  last_updated: 2012-09-01 23:41:51 UTC
},
{
  type: 'home',
  value: '555-555-5551',
  last_updated: 2012-02-11 12:21:11 UTC
}
]
</code></pre>

<p>}
```</p>

<p>To find this document by a phone number is easy:</p>

<p><code>javascript finding a person by phone number
 db.persons.find({'contacts.value':'555-555-5555'})
</code></p>

<p>But what if you wanted to find the <code>contact</code> that was recently updated, say since the beginning of the month, and change its value or add some additional meta-data? The query <em>you'd like</em> would look something like:</p>

<p><code>javascript finding via last_updated
db.persons.find({'contacts.last_updated': {$gte: datetime(2012, 8, 1)}})
</code></p>

<p>This query works and will match the person 'Andrew Glover' -- but the catch here is that what is returned is the entire document. You can add query limiters if you'd like (i.e. <code>{contacts:1}</code>), however, that will merely return a <code>person</code> document with only a collection of <code>contacts</code>. Thus, you are left to iterate over the resultant collection of <code>contacts</code> and work your magic that way. That is, you still have to find the contact document that was edited this month! In your code!</p>

<p>No big deal, you say? This particular example is, indeed, a bit contrived; however, imagine if the overall document is quite large (maybe it's not a <code>person</code> but an <code>organization</code>!) and that the embedded collection is also lengthly (how many employees does Google have?). Now this simple update is pulling a lot of bytes across the wire (and taxing Mongo in the process) and then your app is working with a lot of bytes in memory (now the document is taxing your app!). Did you want this operation to happen quickly, under load too?</p>

<p>Thus, with embedded document collections, if you envision having to work with a particular embedded document <em>in isolation</em>, it is better, at this point, to model has-a relationships with distinct collections (i.e. in this example, life would be much easier if there is a <code>person</code> collection and a <code>contacts</code> one). Indeed, the flexibility of document-oriented, schema-less data stores is a boon to rapid evolutionary development. But you still have to do some thinking up front. Unless, of course, you're a masochist.</p>

<p>I'm a huge fan of Mongo. Check out some of the articles, videos, and podcasts that I've done, which focus on Mongo, including:</p>

<ul>
<li><a href="http://www.ibm.com/developerworks/java/library/j-javadev2-12/">Java development 2.0: MongoDB: A NoSQL datastore with (all the right) RDBMS moves</a></li>
<li><a href="http://public.dhe.ibm.com/software/dw/demos/jmongodb/index.html">Video demo: An introduction to MongoDB</a></li>
<li><a href="http://www.ibm.com/developerworks/java/library/j-gloverpodcast/#Horowitz">Eliot Horowitz on MongoDB</a></li>
<li><a href="http://www.ibm.com/developerworks/java/library/j-gloverpodcast4/index.html#francia">10gen's Steve Francia talks MongoDB</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Modeling Mongo documents with Mongoose]]></title>
    <link href="http://aglover.github.com/blog/2012/08/29/modeling-mongo-documents-with-mongoose/"/>
    <updated>2012-08-29T21:45:00-04:00</updated>
    <id>http://aglover.github.com/blog/2012/08/29/modeling-mongo-documents-with-mongoose</id>
    <content type="html"><![CDATA[<p>Without a doubt, one of the quickest ways to build an application that leverages <a href="http://www.mongodb.org/">MongoDB</a> is with Node. It's as if the two platforms were made for each other; the sheer number of Node libraries available for dealing with Mongo is testimony to a vibrant, innovative community. Indeed, one of my favorite Mongo focused libraries these days is <a href="http://mongoosejs.com/">Mongoose</a>.</p>

<p>Briefly, Mongoose is an object modeling framework that makes it incredibly easy to model collections and ultimately work with intuitive objects that support a rich feature set. Like most things in Node, it couldn't be any easier to get set up. Essentially, to use Mongoose, you'll need to define <code>Schema</code> objects -- these are your documents -- either top level or even embedded.</p>

<p>For example, I've defined a <code>words</code> collection that contains documents (representing...words) that each contain an embedded collection of <code>definition</code> documents. A sample document looks like this:</p>

<p>``` javascript Word Document
{<br/>
  _id: "4fd7c7ac8b5b27f21b000001",<br/>
  spelling: "drivel",
  synonyms: ["garbage", "dribble", "drool"],
  definitions: [
  { part_of_speech: "noun",</p>

<pre><code>definition:"saliva flowing from the mouth, or mucus from the nose; slaver."
</code></pre>

<p>  },
  { part_of_speech: "noun",</p>

<pre><code>definition:"childish, silly, or meaningless talk or thinking; nonsense; twaddle." 
</code></pre>

<p>  }]
}
```</p>

<p>From an document modeling standpoint, I'd like to work with a <code>Word</code> object that contains a list of <code>Definition</code> objects and a number of related attributes (i.e. synonyms, parts of speech, etc). To model this relationship with Mongoose, I'll need to define two <code>Schema</code> types and I'll start with the simplest:</p>

<p><code>javascript Definition Schema
Definition = mongoose.model 'definition', new mongoose.Schema({
  part_of_speech : { type: String, required: true, trim: true, enum: ['adjective', 'noun', 'verb', 'adverb'] },
  definition : {type: String, required: true, trim: true}
})
</code></p>

<p>As you can see, a <code>Definition</code> is simple -- the <code>part_of_speech</code> attribute is an enumerated <code>String</code> that's required; what's more, the <code>definition</code> attribute is also a required <code>String</code>.</p>

<p>Next, I'll define a <code>Word</code>:</p>

<p><code>javascript Word Schema
Word = mongoose.model 'word', new mongoose.Schema({
  spelling : {type: String, required: true, trim: true, lowercase: true, unique: true},
  definitions : [Definition.schema],
  synonyms : [{ type: String, trim: true, lowercase: true }]
})
</code></p>

<p>As you can see, a <code>Word</code> instance embeds a collection of <code>Definition</code>s. Here I'm also demonstrating the usage of <code>lowercase</code> and the index <code>unique</code> placed on the <code>spelling</code> attribute.</p>

<p>To create a <code>Word</code> instance and save the corresponding document couldn't be easier. Mongo array's leverage the <code>push</code> command and Mongoose follows this pattern to the tee.</p>

<p><code>javascript saving with Mongoose
word = new models.Word({spelling : 'loquacious'})
word.synonyms.push 'verbose'
word.definitions.push {definition: 'talking or tending to talk much or freely; talkative; \
  chattering; babbling; garrulous.', part_of_speech: 'adjective' }
word.save (err, data) -&gt;
</code></p>

<p>Finding a word is easy too:</p>

<p>``` javascript findOne in action
it 'findOne should return one', (done) ->
  models.Word.findOne spelling:'nefarious', (err, document) -></p>

<pre><code>document.spelling.should.eql 'nefarious'
document.definitions.length.should.eql 1
document.synonyms.length.should.eql 2
document.definitions[0]['part_of_speech'].should.eql 'adjective'
done(err)
</code></pre>

<p>```</p>

<p>In this case, the above code is a <a href="http://visionmedia.github.com/mocha/">Mocha</a> test case (which uses <a href="https://github.com/visionmedia/should.js">should</a> for assertions) that demonstrates Mongoose's <code>findOne</code>.</p>

<p>You can find the code for these examples and more at my Github repo dubbed <a href="https://github.com/aglover/exegesis">Exegesis</a> and while you're at it, check out the <a href="http://www.ibm.com/developerworks/training/kp/j-kp-node/index.html">developerWorks videos I did for Node</a>!</p>
]]></content>
  </entry>
  
</feed>
