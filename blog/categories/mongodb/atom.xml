<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: MongoDB | The Disco Blog]]></title>
  <link href="http://aglover.github.com/blog/categories/mongodb/atom.xml" rel="self"/>
  <link href="http://aglover.github.com/"/>
  <updated>2013-03-25T18:39:24-04:00</updated>
  <id>http://aglover.github.com/</id>
  <author>
    <name><![CDATA[Andrew Glover]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[2013 Open Analytics Summit]]></title>
    <link href="http://aglover.github.com/blog/2013/03/21/2013-open-analytics-summit/"/>
    <updated>2013-03-21T15:21:00-04:00</updated>
    <id>http://aglover.github.com/blog/2013/03/21/2013-open-analytics-summit</id>
    <content type="html"><![CDATA[<p><img class="right left" src="http://www.openanalyticssummit.com/wp-content/uploads/2012/12/OAS-logo-Full-colour3-300x85.png">On March 25, 2013, <a href="http://www.openanalyticssummit.com/speakers/">I'll be speaking</a> at the <a href="http://www.openanalyticssummit.com/">Open Analytics Summit in Washington DC</a>; specifically, I'll be discussing how the <a href="http://www.app47.com/2013/03/20/next-monday-app47-cto-andy-glover-offers-a-database-reality-check-at-the-open-analytics-summit/">App47</a> team has used <a href="http://www.mongodb.org/">MongoDB</a> as the backend of our enterprise mobile application management platform. We've learned quite a few things about <a href="http://thediscoblog.com/blog/categories/mongodb/">Mongo</a> over the last two years! In the process of growing from a few gigabytes of data a month to over a terabyte/month, we've found out first hand what <a href="http://www.ibm.com/developerworks/training/kp/j-kp-mongo/">Mongo</a> is good at and what it's <em>not good at</em>. I'll be addressing a number of tips, techniques, and strategies -- if you are a Mongo user or planning on being one, come on by!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Everything you need to know about MongoDB]]></title>
    <link href="http://aglover.github.com/blog/2013/02/23/everything-you-need-to-know-about-mongodb/"/>
    <updated>2013-02-23T09:39:00-05:00</updated>
    <id>http://aglover.github.com/blog/2013/02/23/everything-you-need-to-know-about-mongodb</id>
    <content type="html"><![CDATA[<p><img class="right" src="/images/mine/mongodb_icon.png">Are you new to <a href="http://www.mongodb.org/">MongoDB</a>? Curious to see what's interesting about it?  Document-oriented databases like MongoDB are vastly different from relational databases in that they don't store data in tables; instead, they store it in the form of documents. From a developer's perspective, document-oriented (or schemaless) data is simpler and <a href="http://thediscoblog.com/blog/2012/09/03/mongodb-from-the-trenches-masochistic-embedded-collections/">far more flexible</a> to manage than relational data. Rather than storing data into a rigid schema of tables, rows, and columns, joined by relationships, documents are written individually, containing whatever data they require.</p>

<p>Among open source, document-oriented databases, MongoDB is often billed as a <a href="http://www.ibm.com/developerworks/library/j-javadev2-12/">NoSQL database with RDBMS features</a>. One example of this is MongoDB's support for dynamic queries that don't require predefined MapReduce functions. MongoDB also comes with an interactive shell that makes accessing its datastore refreshingly easy, and its out-of-the-box support for sharding and clustering (via <a href="http://thediscoblog.com/blog/2012/09/11/mongodb-from-the-trenches-prudent-production-planning/">replica sets</a>) enables high scalability across multiple nodes.</p>

<p>Check out this IBM developerWorks' Knowledge Path dubbed "<a href="http://www.ibm.com/developerworks/training/kp/j-kp-mongo/">Discover MongoDB</a>" -- watch four videos, read a few articles, listen to a podcast and learn everything you need to know about MongoDB!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Savvy Mongo query selector: exists]]></title>
    <link href="http://aglover.github.com/blog/2013/01/04/savvy-mongo-query-selector-exists/"/>
    <updated>2013-01-04T11:57:00-05:00</updated>
    <id>http://aglover.github.com/blog/2013/01/04/savvy-mongo-query-selector-exists</id>
    <content type="html"><![CDATA[<p><a href="http://www.mongodb.org/">MongoDB</a> supports a <a href="http://docs.mongodb.org/manual/applications/read/">rich query language</a>; in fact, its support of dynamic queries is one of its <a href="http://public.dhe.ibm.com/software/dw/demos/jmongodbdocs/index.html">more distinguishing features</a> compared to other datastores in the <a href="http://www.infoworld.com/d/data-management/flexing-nosql-mongodb-in-review-185922">NoSQL</a> world. Mongo's query language has a variety of query selectors that enable you to <a href="http://www.ibm.com/developerworks/training/kp/j-kp-mongo/">fashion some powerful document searches</a>. One particular <a href="http://docs.mongodb.org/manual/reference/operators/#element">query selector that comes in handy</a> from time to time is <code>$exists</code>.</p>

<p>Because <a href="http://www.ibm.com/developerworks/java/library/j-javadev2-12/">Mongo is document oriented</a> and thus lacks a rigid schema, documents (for better or for worse) can have varying structures within a collection. In practice, you probably don't see vastly differing documents within a collection; however, from time to time, various document fields might differ (as in, <em>they might not be present</em>). Take for example, the classic example of a business card: some cards (i.e. documents) might list a fax number while others might omit it. As another example, as an application and its corresponding data evolves, new fields might be added (or removed).</p>

<p>The <code>$exists</code> query selector facilitates finding documents that have (or do not have) specific fields. On more than one occasion, I've employed this query selector to find documents in need of a surgical update. For example, in a collection dubbed <code>words</code> with word documents that each contain an embedded <code>definitions</code> document collection, I can find those particular definitions that do not have a <code>part_of_speech</code> element like so:</p>

<p><code>javascript $exists query selector in action
db.words.find({"definitions.part_of_speech":{"$exists":false}}).sort({"spelling":1}).limit(100)
</code></p>

<p>Note that the <code>$exists</code> query selector takes a boolean -- <code>true</code> or <code>false</code>.</p>

<p>As you can probably ascertain, Mongo's <code>$exists</code> is slightly <a href="http://www.techonthenet.com/sql/exists.php">different than SQL's</a> <code>exists</code> -- in fact, in SQL there is no way to fashion a query to find a row not containing a column! Can you dig it?</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Pushing Mongo GridFS files with Sinatra]]></title>
    <link href="http://aglover.github.com/blog/2012/12/21/pushing-mongo-gridfs-files-with-sinatra/"/>
    <updated>2012-12-21T21:19:00-05:00</updated>
    <id>http://aglover.github.com/blog/2012/12/21/pushing-mongo-gridfs-files-with-sinatra</id>
    <content type="html"><![CDATA[<p><a href="http://www.app47.com/">We</a> recently implemented a new feature that required two interesting aspects: storing a file in <a href="http://www.mongodb.org/">MongoDB</a> using <a href="http://docs.mongodb.org/manual/applications/gridfs/">GridFS</a> (think traditional <a href="http://en.wikipedia.org/wiki/Binary_large_object">Blob</a>) and then pushing that file down to a browser. Along the way, I discovered a lot of questions on <a href="http://stackoverflow.com/">stackoverflow</a> and the like pertaining to various aspects of GridFS and <a href="http://www.sinatrarb.com/">Sinatra</a> pushes, so I thought I'd explain what we did.</p>

<p>First off, GridFS is a specification for storing and retrieving large documents. In essence, Mongo breaks a large document into smaller documents (called <em>chunks</em>) and stores them in one collection and associates the meta data related to the aggregated chunks into another collection. It's a fairly handy feature and in our case, it made sense to use <a href="http://docs.mongodb.org/manual/faq/developers/#faq-developers-when-to-use-gridfs">GridFS</a> rather than <a href="http://aws.amazon.com/s3/">S3</a> (or the underlying file system).</p>

<p>All MongoDB drivers implement a similar access pattern to leverage GridFS and they hide the complexity of working with chunks. For example, <a href="https://github.com/mongodb/mongo-ruby-driver">the Ruby driver</a> simply provides a <a href="https://github.com/mongodb/mongo-ruby-driver/wiki/GridFS">single interface to manage the two GridFS collections</a>. In fact, <a href="https://github.com/mongodb/mongo-ruby-driver/blob/master/lib/mongo/gridfs/grid.rb">the interface</a> basically provides two methods: <code>get</code> &amp; <code>put</code> which might seem somewhat limiting, especially because <code>get</code> takes an <code>_id</code>! What's more, you can add rich meta data to a GridFS document (via the <code>put</code> call) -- data you'd conceivably want to query by, but at first glance, you can't via the <code>get</code> method. Nevertheless, because GridFS is ultimately two collections in Mongo, you can query them as you would any other collection.</p>

<p>Thus, finding files by some attribute other than their <code>_id</code> is as easy as writing the corresponding query:</p>

<p><code>ruby GridFS example
file = @mongo['user_apks.files'].find({:filename =&gt; user_id.to_s}).first
</code></p>

<p>Keep in mind, however, that the result returned above is a JSON document -- i.e. the variable <code>file</code> above isn't a pointer to an actual I/O instance but simply a JSON document with its details. To get the actual file, use the <code>get</code> method provided by the driver's GridFS facade -- this'll handle the details of grabbing the file from GridFS. The <code>get</code> method takes an <code>_id</code>, which you can get from the <code>file</code> document. Thus, to get an instance of a readable file, you can grab it like so:</p>

<p><code>ruby get via _id
@grid.get(file['_id'])
</code></p>

<p>Thus, with the <code>get</code> call you can actually get ahold of a file instance and not some JSON document describing it.</p>

<p>To push this instance down to a browser using <a href="http://thediscoblog.com/blog/2012/12/10/sinatra-coffeescript-and-haml-swinging-in-4-steps/">Sinatra</a>, you need to do 3 things:</p>

<ul>
<li>set the content type</li>
<li>set the attachment name</li>
<li>write the file to the response</li>
</ul>


<p>In our case, the file is an <a href="http://developer.android.com/index.html">Android</a> app; accordingly, the content type is <code>application/vnd.android.package-archive</code> and as you'll note, the attachment is simply the name of the <code>.apk</code> file. Finally, the response to the request is written to by <em>reading</em> from the corresponding GridFS file:</p>

<p><code>ruby Sinatra push
get '/some/url/:account_id/:user_id', :agent =&gt; /Android/ do |account_id, user_id|
  file = # get the file from GridFS
  content_type 'application/vnd.android.package-archive'
  attachment "#{file.filename}.apk"
  response.write file.read
end
</code>
As you can see, it's all quite easy -- GridFS is simply a facade for two collections; moreover, forcing a download in Sinatra is three straightforward steps. Can you dig it, man?</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[MongoDB from the trenches: prudent production planning]]></title>
    <link href="http://aglover.github.com/blog/2012/09/11/mongodb-from-the-trenches-prudent-production-planning/"/>
    <updated>2012-09-11T11:34:00-04:00</updated>
    <id>http://aglover.github.com/blog/2012/09/11/mongodb-from-the-trenches-prudent-production-planning</id>
    <content type="html"><![CDATA[<p><img class="left" src="/images/mine/mongodb_icon.png">While starting out with <a href="http://http://www.Mongodb.org/">MongoDB</a> is super easy, there are few things you should keep in mind as you move from a development environment into a production one. No one wants to get paged at 3am because a customer can’t complete an order on your awesome e-commerce site because your database isn’t responding fast enough or worse, is down.</p>

<p>Planning for a production deployment with MongoDB <a href="http://www.mongodb.org/display/DOCS/Production+Notes">isn't rocket science</a>, but I must warn you, it'll cost money, especially if your application actually gets used <em>a lot</em>, which is every developer's dream. Therefore, like all databases, you need to plan for high availability and you’ll want the maximum performance benefits you can get for your money in a production environment.</p>

<p>First and foremost, <a href="http://www.mongodb.org/display/DOCS/Caching">Mongo likes memory</a>; that is, frequently accessed data is stored directly in memory; moreover, writes are also stored in memory until being flushed to disk. It’s imperative that you provide enough memory for Mongo to store a valid working dataset; otherwise, Mongo will have to go to the disk to retrieve, what should be, fast lookups via indexed data. This is sloooooow. Therefore, a good rule of thumb is to plan to run your Mongo instances with <em>as much memory as you can afford</em>.</p>

<p>You can get an idea for your working data set by running <code>Mongostat</code> -- this is a handy command line utility that’ll give you a second-by-second view into what Mongo is up to -- one particular metric you’ll see is resident memory (labeled as <code>res</code>) -- this will give you a good idea of how much memory Mongo’s using at any given moment. If this number exceeds what you have available on a given machine, then Mongo is having to go to disk, which is going to be a lot slower.</p>

<p>Not all data can be stored in memory; every document in Mongo is eventually written to disk. And like always, I/O is always a slow operation compared to working with memory. This is why, for example, writes in Mongo can be so fast -- drivers allow you to, essentially, fire and forget and the actual write to disk is done later, asynchronously. Reads can also incur an I/O penalty when something requested isn’t in working memory.</p>

<p>Thus, for high performance reads and writes, <em>pay attention to the underlying disks</em>. A key metric here is IOPS or input/output operations per second. Mongo will be extremely happy, for example, <a href="http://www.mongodb.org/display/DOCS/SSD">in an SSD environment</a>, provided you can afford it. <a href="http://en.wikipedia.org/wiki/IOPS">Just take a look at various IOPS comparisons between SSDs and traditional spinning disks</a> -- super fast RPM disks can achieve IOPS in the 200 range. Typical SSD drives are attaining wild numbers, orders of magnitude higher (like in the 100’s of thousands of IOPS). It’s crazy how fast SSDs are compared to traditional hard drives.</p>

<p>RAM is still faster than SSDs, so you’ll still want to understand your working set of data and ensure you have plenty of memory to contain it.</p>

<p>Finally, for maximum availably, <em>you really should be using Mongo’s <a href="http://www.mongodb.org/display/DOCS/Replica+Sets">replica sets</a></em>. Setting up a cluster of Mongo instances is so incredibility easy that there really isn’t a good reason not to do it. The benefits of doing so are manifold, including:</p>

<ul>
<li>data redundancy</li>
<li>high availability via automated failover</li>
<li>disaster recovery</li>
</ul>


<p>Plus, running a replica set makes maintenance so much easier as you can bring nodes off line and on line w/out an interruption of service. And you can run nodes in a replica set on commodity hardware (don’t forget about my points regarding memory and I/O though).</p>

<p>Accordingly, when looking to move Mongo into a production environment, you need to consider memory, I/O performance, and replica sets. Running a high performant, high availability replica set'ed Mongo, not surprisingly, will cost you. If you're looking for options for running Mongo in a production environment, I can't recommend enough the team at <a href="https://mongohq.com/">MongoHQ</a>.</p>

<p>I'm a huge fan of Mongo. Check out some of the articles, videos, and podcasts that I've done, which focus on Mongo, including:</p>

<ul>
<li><a href="http://www.ibm.com/developerworks/java/library/j-javadev2-12/">Java development 2.0: MongoDB: A NoSQL datastore with (all the right) RDBMS moves</a></li>
<li><a href="http://public.dhe.ibm.com/software/dw/demos/jmongodb/index.html">Video demo: An introduction to MongoDB</a></li>
<li><a href="http://www.ibm.com/developerworks/java/library/j-gloverpodcast/#Horowitz">Eliot Horowitz on MongoDB</a></li>
<li><a href="http://www.ibm.com/developerworks/java/library/j-gloverpodcast4/index.html#francia">10gen's Steve Francia talks MongoDB</a></li>
</ul>

]]></content>
  </entry>
  
</feed>
