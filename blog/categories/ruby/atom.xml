<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Ruby | The Disco Blog]]></title>
  <link href="http://thediscoblog.com/blog/categories/ruby/atom.xml" rel="self"/>
  <link href="http://thediscoblog.com/"/>
  <updated>2013-07-15T15:45:34-04:00</updated>
  <id>http://thediscoblog.com/</id>
  <author>
    <name><![CDATA[Andrew Glover]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Lickety-split custom validations in Rails]]></title>
    <link href="http://thediscoblog.com/blog/2013/06/12/lickety-split-custom-validations-in-rails/"/>
    <updated>2013-06-12T13:19:00-04:00</updated>
    <id>http://thediscoblog.com/blog/2013/06/12/lickety-split-custom-validations-in-rails</id>
    <content type="html"><![CDATA[<p>Have a highly specific, yet custom validation for a particular field on one of your <a href="http://thediscoblog.com/blog/categories/rails/">Rails</a> model objects? Don't want to create a <code>ActiveModel::Validator</code> type? Not a problem!</p>

<p>You can just as easily <a href="http://guides.rubyonrails.org/active_record_validations_callbacks.html">create a method</a> that can be invoked as part of the validation process. For example, imagine a field dubbed <code>uri</code> in some model object; this field must begin with a protocol (i.e. http or https). You can create a validation method like so:</p>

<p>``` ruby Custom validator
def uri_should_start_with_protocol
  if !uri.start_with?('http://') &amp;&amp; !uri.start_with?('https://')</p>

<pre><code>errors.add(:uri, 'Web Address should start with http:// or https://')
</code></pre>

<p>  end
end
```
This method resides in your model. You can then register this method as a validation for your model like so:</p>

<p><code>ruby Wiring the validation
validate :uri_should_start_with_protocol
</code></p>

<p>Now if the <code>uri</code> field doesn't contain http or https, <code>model.save</code> will return <code>false</code>. Done!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Backgrounding tasks in Heroku with Delayed Job]]></title>
    <link href="http://thediscoblog.com/blog/2013/06/10/backgrounding-tasks-in-heroku-with-delayed-job/"/>
    <updated>2013-06-10T12:56:00-04:00</updated>
    <id>http://thediscoblog.com/blog/2013/06/10/backgrounding-tasks-in-heroku-with-delayed-job</id>
    <content type="html"><![CDATA[<p><img class="right" src="/images/mine/heroku-logo-light.png">Long running web requests are bad. They create resource contention among other waiting incoming requests; what's more, with HTTP servers like <a href="https://github.com/defunkt/unicorn">Unicorn</a> (which is rapidly becoming the de facto HTTP server for Rails apps running on <a href="https://get.heroku.com/">Heroku</a>), long running requests are summarily terminated after some threshold (for example, 30 seconds) leaving users with a nasty timeout error (and, of course, other users complaining that it takes forever for your site to do anything). Luckily, with frameworks like <a href="https://github.com/collectiveidea/delayed_job">Delayed Job</a>, backgrounding long running tasks <a href="https://devcenter.heroku.com/articles/delayed-job">couldn't be any easier</a>.</p>

<!-- more -->


<p>To leverage Delayed Job in Heroku, you'll need for follow a few steps. In my case, since I'm using <a href="http://mongoid.org/en/mongoid/index.html">Mongoid</a>, I'm going to use an <a href="https://github.com/collectiveidea/delayed_job_mongoid">alternate Active Record Delayed Job tie-in</a> dubbed <code>delayed_job_mongoid</code>. The reason for this <a href="http://guides.rubyonrails.org/">Active Record</a> integration will become obvious once I show you how to actually force a long running task to be asynchronous. Regardless if you are using Mongoid or not, the Active Record integration is identical.</p>

<p>First and foremost, you'll need to add <code>delayed_job_mongoid</code> to your <code>Gemfile</code> (or if you aren't using Mongoid, add <code>delayed_job_active_record</code>).  Delayed Job stores jobs in your database; consequently, after you run <code>bundle install</code>, proceed to update your underlying MongoDB instance with a new index by running:</p>

<p><code>bash Adding an index and new collection to MongoDB
$&gt; script/rails runner 'Delayed::Backend::Mongoid::Job.create_indexes'
</code></p>

<p>Obviously, if you're using a normal RDMBS, your command will be slightly different (i.e. <code>rake db:migrate</code>).</p>

<p>After that step is complete, you'll need to generate a <code>delayed_job</code> script via:</p>

<p><code>bash Generating the Delayed Job script
$&gt; rails generate delayed_job
</code></p>

<p>This script allows to you execute the Delayed Job framework with a number of options. As it turns out, you don't really need this script as Delayed Job hooks into Rake as well; it is via the Rake integration that Heroku will work with Delayed Job.</p>

<p>Now that you've set up 80% of the infrastructure required to support Delayed Job, you next need to background some long running task. This is the fun part and like everything else so far, it couldn't be any easier.</p>

<p>Delayed Job hooks directly into Active Record and thus, you can background some unit of work on a model object by inserting a <code>delay</code> call. For example, in my case, I had a <code>Group</code> model object that when updated under certain circumstances required that <em>all associated</em> users also be updated (wouldn't it be nice if <a href="https://jira.mongodb.org/browse/SERVER-124">MongoDB supported triggers</a>?). As you can imagine, updating hundreds of users is rather time intensive.</p>

<p>Thus, the user update logic was thrown into a special method (dubbed <code>aysnc_update_users</code>) and was then invoked like so:</p>

<p><code>ruby Adding in a delay backgrounds the async_update_users call
group.delay.async_update_users
</code></p>

<p>This call essentially serializes the logic here into a collection called <code>delayed_backend_mongoid_jobs</code> which can then be invoked asynchronously by another process. And therein lies your last few steps.</p>

<p>Heroku has the notion of <a href="https://devcenter.heroku.com/articles/background-jobs-queueing">worker dynos</a>, which are background processors -- think of worker dynos as engines capable of doing what ever you want them to do. In the case of Delayed Job, you want those worker dynos to invoke jobs residing in the <code>delayed_backend_mongoid_jobs</code> collection (which is conceptually a queue).</p>

<p>To configure a worker dyno, you'll need to do 2 things. First, provision one like so:</p>

<p><code>bash Using Heroku CLI to fire up a worker dyno
$&gt; heroku ps:scale worker=1
</code></p>

<p>You'll then need to update your <code>Procfile</code> to include the command the worker dyno should invoke:</p>

<p><code>ruby Updated Procfile command
worker:  bundle exec rake jobs:work
</code></p>

<p>As you can see, the worker dyno in this case is invoking a <a href="http://rake.rubyforge.org/">Rake task</a> (<code>jobs:work</code>) which is asynchronously polling for new jobs in your conceptual queue and invoking them as they are found.</p>

<p>Finally, deploy to Heroku and keep an eye on the queue for jobs -- you can isolate the dyno workers logs via</p>

<p><code>
$&gt; heroku logs -p worker -t
</code></p>

<p>Was that easy or what?</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[The Rails, CloudFront, and Heroku performance hat-trick]]></title>
    <link href="http://thediscoblog.com/blog/2013/05/01/the-rails-cloudfront-and-heroku-performance-hat-trick/"/>
    <updated>2013-05-01T09:10:00-04:00</updated>
    <id>http://thediscoblog.com/blog/2013/05/01/the-rails-cloudfront-and-heroku-performance-hat-trick</id>
    <content type="html"><![CDATA[<p><img class="right" src="/images/mine/hat-trick.png"><a href="http://aws.amazon.com/cloudfront/">Amazon CloudFront</a> is a pay-as-you-go global <a href="http://en.wikipedia.org/wiki/Content_delivery_network">content delivery network</a> (or CDN) that provides high availability and high performance serving of static assets. Basically, it means users have to wait less time to view your web app regardless of their location on the globe.</p>

<p>It's easy to configure a <a href="http://rubyonrails.org/">Rails</a> app to take advantage of CloudFront; what's more, if your Rails app is hosted on <a href="http://www.ibm.com/developerworks/java/library/j-javadev2-21/">Heroku</a>, there's <a href="https://github.com/romanbsd/heroku-deflater">a nifty gem</a>, dubbed heroku-deflater, that'll enable <a href="http://en.wikipedia.org/wiki/HTTP_compression">HTTP compression</a> of static assets (<a href="http://stackoverflow.com/questions/12326191/any-way-to-serve-gzip-assets-from-heroku">other than images</a>).</p>

<p>To get these three entities to play nicely together requires a few simple steps. Let me show you how.</p>

<!--more-->


<p>First, if you want to enable HTTP gzip compression of static assets other than images from a Heroku app, then add the heroku-deflater gem to your <code>Gemfile</code>. This gem doesn't compress images as in some cases, zipping images creates bigger ones!</p>

<p>Once you've run <code>bundle install</code> and deployed your app to Heroku, fire up a terminal and run <code>[cURL](http://thediscoblog.com/blog/2013/04/18/curling-for-wget/)</code> to verify that the HTTP response Content-Encoding is gzip like so:</p>

<p><code>bash cURL testing gzip response
curl -i -H "Accept-Encoding: gzip,deflate" http://your.awesome.web.app
</code></p>

<p>You should see in the response this key phrase:</p>

<p><code>bash cURL response
Content-Encoding: gzip
</code></p>

<p>If you do see the Content-Encoding set to gzip, then you are good to go. If, for some reason, you don't see it, check your environment's configuration file (which you will have to edit to get CloudFront working anyway) and verify that the property <code>config.serve_static_assets</code> is set to <code>true</code>.</p>

<p>Next, sign into the AWS Management Console and enable CloudFront if you haven't already. From the CloudFront admin page, create a new distribution via the Create Distribution button on the top left.</p>

<p><img class="center" src="/images/mine/cloudfront_1.png"></p>

<p>Once the create distribution wizard begins, be sure to select Download as your delivery method.</p>

<p><img class="center" src="/images/mine/cloudfront_2.png"></p>

<p>In the next screen, there are some important fields you'll need to fill out, namely: the Origin Source Name and the Viewer Protocol Policy. For the Origin Source Name, you will need to put in your app's URL or the Heroku URL (if you do not map a custom domain name to it). If you web site supports HTTPS, then be sure to set the Viewer Protocol Policy to HTTP and HTTPS.</p>

<p><img class="center" src="/images/mine/cloudfront_3.png"></p>

<p>The only other important setting after these two is the Price Class. It's here where you can set where CloudFront will essentially serve up your content -- the default setting of Use All Edge Locations is most likely what you need.</p>

<p><img class="center" src="/images/mine/cloudfront_5.png"></p>

<p>Finally, click the Create Distribution button -- once you do that, it'll take a bit for things to initialize (basically, the CDN needs to get built and this may take up to 30 minutes).</p>

<p>Now to configure your Rails app, you'll need to open up your target environment's configuration file (i.e. <code>production.rb</code>). The <a href="http://bindle.me/blog/index.php/395/caches-cdns-and-heroku-cedar">two fields</a> you'll want to be sure are properly set are <code>serve_static_assets</code> and <code>static_cache_control</code>. In particular, you are setting the cache control variable to one year. This means that once a static asset, like a JavaScript file is downloaded to the browser, it'll be cached for one year. Don't fret, however, if you think that'll inhibit change -- the file that is ultimately downloaded has a hash attached to it (via the magic of <a href="http://guides.rubyonrails.org/asset_pipeline.html">Rail's Asset Pipeline</a>). Consequently, the file that is cached is something like <code>your_js_file-asdf098203820980a980</code> where that last bit is a hash value that'll change if the file itself changes.</p>

<p><code>ruby production.rb edited to support CDN
config.serve_static_assets = true
config.static_cache_control = 'public, max-age=31536000'
</code></p>

<p>The last change you need to make to your environment file is to set the <code>asset_host</code> to the CloudFront domain that you just created. You can find this in your AWS Management Console -- it'll be a cryptic URL like http://asdjlkj2321.cloudfront.net.</p>

<p><code>ruby production.rb edited to support asset host
config.action_controller.asset_host = 'the domain name from AWS Dashboard'
</code></p>

<p>Commit your changes and deploy your app.</p>

<p>To verify things are kosher, you'll need to give it some time (check the status of your CloudFront CDN -- if it's status is Enabled then you are good to go!). If things are ready, then fire up a browser and go to your app.</p>

<p>In this case, <a href="http://thediscoblog.com/blog/2013/04/15/chromes-console-commands/">I'm using Chrome</a>. Go to JavaScript console and hit the Network tab.</p>

<p><img class="center" src="/images/mine/cloudfront_6.png"></p>

<p>Surf around and you'll note a few things -- one, that the assets like images and JavaScript files are being severed up from your CDN (just look at the URL) and that the size will often say "(from cache)" -- that means the CDN is handling the load rather than <a href="http://www.ibm.com/developerworks/podcast/glover-heroku-110811/">Heroku</a>. You should also note that your web app is probably a bit more snappy!</p>

<p><img class="center" src="/images/mine/cloudfront_7.png"></p>

<p>Check out your Heroku logs and you'll note fewer hits in this case -- dynamic pages are still being loaded, however, static assets are not anymore -- that's the job of your CDN!</p>

<p>CloudFront isn't free; nevertheless, I think you'll find the corresponding cost quite reasonable. Pricing will vary depending on how much content you'll be serving up with CloudFront -- this is a function of how many visitors you have <em>along with</em> how many static assets that are ultimately downloaded to a user's browser. For instance, 500GB of average content will cost you less than $75/month.</p>

<p>CloudFront's pay-as-you-go model makes it extremely affordable to add a nice bit of pep to your app's performance along with using gzip compression and HTTP caching. And hopefully as I've shown you, it's rather easy to do with a Rails app running on Heroku.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Mongoid batch inserts]]></title>
    <link href="http://thediscoblog.com/blog/2013/03/27/mongoid-batch-inserts/"/>
    <updated>2013-03-27T11:34:00-04:00</updated>
    <id>http://thediscoblog.com/blog/2013/03/27/mongoid-batch-inserts</id>
    <content type="html"><![CDATA[<p>In SQL land, all databases support batch inserts. Batch inserts are an effective and efficient mechanism to insert a lot of similar data. That is, instead of issuing x insert statements, you execute 1 insert with x records. This is much more efficient because the insert statement doesn't need to be re-parsed x times, there is only 1 network trip as opposed to x, and in the case of transactions, there is only 1 transaction instead of x. When compared to x inserts, batch inserts are always faster.</p>

<p>As it turns out, <a href="http://www.mongodb.org/">MongoDB</a> supports <a href="http://docs.mongodb.org/manual/applications/create/#bulk-insert-multiple-documents">batch inserts</a>! And just like in SQL land, Mongo's batching feature is much faster at inserting a lot of data in one insert rather than x inserts.</p>

<p>For example, the <a href="https://github.com/mongodb/mongo-ruby-driver">Mongo Ruby driver</a>'s <a href="https://github.com/mongodb/mongo-ruby-driver/blob/master/lib/mongo/collection.rb#L371">insert method takes a collection</a>; thus, you can insert an array of hashes quite efficiently. Even if you are using a <a href="http://mongoid.org/en/mongoid/index.html">ODM like Mongoid</a>, you can still perform batch inserts as all you need to do is get a reference to the model object's underlying collection and then issue an <code>insert</code> with an array of hashes matching the collection's intended document structure.</p>

<p>For instance, to insert a collection of <code>Tag</code> models (each having 3 fields: <code>name</code>, <code>system_tag</code>, and <code>account_id</code>) in one fell swoop I can do the following:</p>

<p><code>ruby Batch inserts with Mongoid model example
tags = ['a', 'bunch', 'of', 'tags'].collect { |tag| {name: tag, system_tag: true, account_id: id} }
Tag.collection.insert tags
</code></p>

<p>In the code above, the <code>insert</code> takes a collection of hashes; what's more, the <code>insert</code> is tied to the <code>tags</code> collection via the <code>Tag.collection</code> call.</p>

<p>Batch inserts are always faster if you have a lot of similar documents -- in our case, we saw a <em>tremendous</em> performance increase when employing batching.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Testing Rails migrations]]></title>
    <link href="http://thediscoblog.com/blog/2013/02/18/testing-rails-migrations/"/>
    <updated>2013-02-18T16:22:00-05:00</updated>
    <id>http://thediscoblog.com/blog/2013/02/18/testing-rails-migrations</id>
    <content type="html"><![CDATA[<p>I recently found myself searching <a href="http://stackoverflow.com/">Stackoverflow</a> and Google for various techniques for automatically testing <a href="http://guides.rubyonrails.org/migrations.html">Rails migrations</a>. I was surprised not to have found <a href="http://stackoverflow.com/questions/6079016/how-do-i-test-rails-migrations">too much</a> information though. While testing a migration is fairly straightforward (migrations are classes and you can easily invoke corresponding methods); the challenge can be setting models up properly. That is, migrations are a tool to update an underlying database to reflect changes in models -- by the time you are writing a migration, the models <em>already</em> reflect what should be.</p>

<p>Accordingly, to test a migration, you need to set up your test with how things were and then run your migration and verify things have migrated.  As it turns out, this is super easy to do with a document oriented database like <a href="http://www.mongodb.org/">MongoDB</a>. For this particular project, we're using <a href="http://mongoid.org/en/mongoid/index.html">Mongoid</a>,  which is an Object-Document-Mapper (or ODM) for MongoDB and we're also using a nifty gem dubbed <a href="https://github.com/adacosta/mongoid_rails_migrations">mongoid_rails_migrations</a>, which facilitates writing Mongoid migrations.</p>

<p>In order to reflect the state of the underlying datastore before running a migration, I needed to remove a particular collection, which due to changes in our models, is automatically populated with meta data when various events occur (think <a href="http://en.wikipedia.org/wiki/Database_trigger">relational trigger</a> here, for example). As you can probably see, as this new collection doesn't exist in production, all the existing data in production needs some corresponding default meta data to reflect the new requirements which brought this collection to life.</p>

<p>Accordingly, once I initialize my models and the corresponding collection is populated, I need to completely <a href="http://docs.mongodb.org/manual/reference/method/db.collection.drop/">drop the collection</a>. Then, I can run my migration and then verify that the previously nuked collection is present with all the required data.</p>

<p>In my case, I'm using <a href="https://github.com/thoughtbot/shoulda">shoulda</a> in concert with <a href="http://ruby-doc.org/stdlib-1.9.3/libdoc/test/unit/rdoc/Test/Unit.html">Test::Unit</a>, but the details of a test framework really don't matter -- in any case, you'll need to load your migration, which can be done via a <code>require</code> statement like so:</p>

<p><code>ruby Requiring a migration
require File.join(Rails.root, 'db', 'migrate', '20130217194234_member_app_roles_permissions')
</code></p>

<p>In my <a href="http://en.wikipedia.org/wiki/Test_fixture">fixture</a> logic, I've initialized a few objects and related them, which automatically creates the aforementioned meta data collection; consequently, I need to do two things. First, get a connection to the underlying test datastore and then drop that collection.</p>

<p><code>ruby Obtaining a connection and dropping a collection
db = @account.db
db['member_app_roles'].drop
</code></p>

<p>Now I'm ready to run my migration -- it's as simple as invoking the <a href="http://www.railstips.org/blog/archives/2009/05/11/class-and-instance-methods-in-ruby/">class method</a> <code>up</code>!</p>

<p><code>ruby Invoking a migration
MemberAppRolesPermissions.up
</code></p>

<p>Once the migration has finished running, I can then verify that everything is cool and copasetic. In this case, I need to go directly to the datastore because those objects in memory won't reflect my changes just yet.</p>

<p>``` ruby Asserting things worked!
member = Member.find(member.id)</p>

<p>assert_equal 2, member.member_app_roles.size
member.member_app_roles.each do |app_role|
  assert_equal 'admin', app_role.role
  assert_equal member, app_role.member
  assert_not_nil app_role.app
end
```</p>

<p>As a benefit of thinking through how to test a migration, you end up unveiling how you'd construct the migration's <code>down</code> method. That is, in my case, to roll back, all I need to do is blow away the <code>member_app_roles</code> collection!</p>

<p>As you can see, testing migrations isn't terribly difficult (probably a good reason why I haven't found too much information about it); the key aspect is the logic that is applied to verify your migration actually worked. It should be noted that while I executed this test in the context of a document oriented database, you could certainly do the same in a relational database. For example, by dropping  columns, tables, etc before running a migration. Either way, testing a migration is a snap. Can you dig it?</p>
]]></content>
  </entry>
  
</feed>
