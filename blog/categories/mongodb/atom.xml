<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: MongoDB | The Disco Blog]]></title>
  <link href="http://aglover.github.com/blog/categories/mongodb/atom.xml" rel="self"/>
  <link href="http://aglover.github.com/"/>
  <updated>2013-04-06T12:22:33-04:00</updated>
  <id>http://aglover.github.com/</id>
  <author>
    <name><![CDATA[Andrew Glover]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Mongoid batch inserts]]></title>
    <link href="http://aglover.github.com/blog/2013/03/27/mongoid-batch-inserts/"/>
    <updated>2013-03-27T11:34:00-04:00</updated>
    <id>http://aglover.github.com/blog/2013/03/27/mongoid-batch-inserts</id>
    <content type="html"><![CDATA[<p>In SQL land, all databases support batch inserts. Batch inserts are an effective and efficient mechanism to insert a lot of similar data. That is, instead of issuing x insert statements, you execute 1 insert with x records. This is much more efficient because the insert statement doesn't need to be re-parsed x times, there is only 1 network trip as opposed to x, and in the case of transactions, there is only 1 transaction instead of x. When compared to x inserts, batch inserts are always faster.</p>

<p>As it turns out, <a href="http://www.mongodb.org/">MongoDB</a> supports <a href="http://docs.mongodb.org/manual/applications/create/#bulk-insert-multiple-documents">batch inserts</a>! And just like in SQL land, Mongo's batching feature is much faster at inserting a lot of data in one insert rather than x inserts.</p>

<p>For example, the <a href="https://github.com/mongodb/mongo-ruby-driver">Mongo Ruby driver</a>'s <a href="https://github.com/mongodb/mongo-ruby-driver/blob/master/lib/mongo/collection.rb#L371">insert method takes a collection</a>; thus, you can insert an array of hashes quite efficiently. Even if you are using a <a href="http://mongoid.org/en/mongoid/index.html">ODM like Mongoid</a>, you can still perform batch inserts as all you need to do is get a reference to the model object's underlying collection and then issue an <code>insert</code> with an array of hashes matching the collection's intended document structure.</p>

<p>For instance, to insert a collection of <code>Tag</code> models (each having 3 fields: <code>name</code>, <code>system_tag</code>, and <code>account_id</code>) in one fell swoop I can do the following:</p>

<p><code>ruby Batch inserts with Mongoid model example
tags = ['a', 'bunch', 'of', 'tags'].collect { |tag| {name: tag, system_tag: true, account_id: id} }
Tag.collection.insert tags
</code></p>

<p>In the code above, the <code>insert</code> takes a collection of hashes; what's more, the <code>insert</code> is tied to the <code>tags</code> collection via the <code>Tag.collection</code> call.</p>

<p>Batch inserts are always faster if you have a lot of similar documents -- in our case, we saw a <em>tremendous</em> performance increase when employing batching.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[2013 Open Analytics Summit]]></title>
    <link href="http://aglover.github.com/blog/2013/03/21/2013-open-analytics-summit/"/>
    <updated>2013-03-21T15:21:00-04:00</updated>
    <id>http://aglover.github.com/blog/2013/03/21/2013-open-analytics-summit</id>
    <content type="html"><![CDATA[<p><img class="right left" src="http://www.openanalyticssummit.com/wp-content/uploads/2012/12/OAS-logo-Full-colour3-300x85.png">On March 25, 2013, <a href="http://www.openanalyticssummit.com/speakers/">I'll be speaking</a> at the <a href="http://www.openanalyticssummit.com/">Open Analytics Summit in Washington DC</a>; specifically, I'll be discussing how the <a href="http://www.app47.com/2013/03/20/next-monday-app47-cto-andy-glover-offers-a-database-reality-check-at-the-open-analytics-summit/">App47</a> team has used <a href="http://www.mongodb.org/">MongoDB</a> as the backend of our enterprise mobile application management platform. We've learned quite a few things about <a href="http://thediscoblog.com/blog/categories/mongodb/">Mongo</a> over the last two years! In the process of growing from a few gigabytes of data a month to over a terabyte/month, we've found out first hand what <a href="http://www.ibm.com/developerworks/training/kp/j-kp-mongo/">Mongo</a> is good at and what it's <em>not good at</em>. I'll be addressing a number of tips, techniques, and strategies -- if you are a Mongo user or planning on being one, come on by!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Everything you need to know about MongoDB]]></title>
    <link href="http://aglover.github.com/blog/2013/02/23/everything-you-need-to-know-about-mongodb/"/>
    <updated>2013-02-23T09:39:00-05:00</updated>
    <id>http://aglover.github.com/blog/2013/02/23/everything-you-need-to-know-about-mongodb</id>
    <content type="html"><![CDATA[<p><img class="right" src="/images/mine/mongodb_icon.png">Are you new to <a href="http://www.mongodb.org/">MongoDB</a>? Curious to see what's interesting about it?  Document-oriented databases like MongoDB are vastly different from relational databases in that they don't store data in tables; instead, they store it in the form of documents. From a developer's perspective, document-oriented (or schemaless) data is simpler and <a href="http://thediscoblog.com/blog/2012/09/03/mongodb-from-the-trenches-masochistic-embedded-collections/">far more flexible</a> to manage than relational data. Rather than storing data into a rigid schema of tables, rows, and columns, joined by relationships, documents are written individually, containing whatever data they require.</p>

<p>Among open source, document-oriented databases, MongoDB is often billed as a <a href="http://www.ibm.com/developerworks/library/j-javadev2-12/">NoSQL database with RDBMS features</a>. One example of this is MongoDB's support for dynamic queries that don't require predefined MapReduce functions. MongoDB also comes with an interactive shell that makes accessing its datastore refreshingly easy, and its out-of-the-box support for sharding and clustering (via <a href="http://thediscoblog.com/blog/2012/09/11/mongodb-from-the-trenches-prudent-production-planning/">replica sets</a>) enables high scalability across multiple nodes.</p>

<p>Check out this IBM developerWorks' Knowledge Path dubbed "<a href="http://www.ibm.com/developerworks/training/kp/j-kp-mongo/">Discover MongoDB</a>" -- watch four videos, read a few articles, listen to a podcast and learn everything you need to know about MongoDB!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Savvy Mongo query selector: exists]]></title>
    <link href="http://aglover.github.com/blog/2013/01/04/savvy-mongo-query-selector-exists/"/>
    <updated>2013-01-04T11:57:00-05:00</updated>
    <id>http://aglover.github.com/blog/2013/01/04/savvy-mongo-query-selector-exists</id>
    <content type="html"><![CDATA[<p><a href="http://www.mongodb.org/">MongoDB</a> supports a <a href="http://docs.mongodb.org/manual/applications/read/">rich query language</a>; in fact, its support of dynamic queries is one of its <a href="http://public.dhe.ibm.com/software/dw/demos/jmongodbdocs/index.html">more distinguishing features</a> compared to other datastores in the <a href="http://www.infoworld.com/d/data-management/flexing-nosql-mongodb-in-review-185922">NoSQL</a> world. Mongo's query language has a variety of query selectors that enable you to <a href="http://www.ibm.com/developerworks/training/kp/j-kp-mongo/">fashion some powerful document searches</a>. One particular <a href="http://docs.mongodb.org/manual/reference/operators/#element">query selector that comes in handy</a> from time to time is <code>$exists</code>.</p>

<p>Because <a href="http://www.ibm.com/developerworks/java/library/j-javadev2-12/">Mongo is document oriented</a> and thus lacks a rigid schema, documents (for better or for worse) can have varying structures within a collection. In practice, you probably don't see vastly differing documents within a collection; however, from time to time, various document fields might differ (as in, <em>they might not be present</em>). Take for example, the classic example of a business card: some cards (i.e. documents) might list a fax number while others might omit it. As another example, as an application and its corresponding data evolves, new fields might be added (or removed).</p>

<p>The <code>$exists</code> query selector facilitates finding documents that have (or do not have) specific fields. On more than one occasion, I've employed this query selector to find documents in need of a surgical update. For example, in a collection dubbed <code>words</code> with word documents that each contain an embedded <code>definitions</code> document collection, I can find those particular definitions that do not have a <code>part_of_speech</code> element like so:</p>

<p><code>javascript $exists query selector in action
db.words.find({"definitions.part_of_speech":{"$exists":false}}).sort({"spelling":1}).limit(100)
</code></p>

<p>Note that the <code>$exists</code> query selector takes a boolean -- <code>true</code> or <code>false</code>.</p>

<p>As you can probably ascertain, Mongo's <code>$exists</code> is slightly <a href="http://www.techonthenet.com/sql/exists.php">different than SQL's</a> <code>exists</code> -- in fact, in SQL there is no way to fashion a query to find a row not containing a column! Can you dig it?</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Pushing Mongo GridFS files with Sinatra]]></title>
    <link href="http://aglover.github.com/blog/2012/12/21/pushing-mongo-gridfs-files-with-sinatra/"/>
    <updated>2012-12-21T21:19:00-05:00</updated>
    <id>http://aglover.github.com/blog/2012/12/21/pushing-mongo-gridfs-files-with-sinatra</id>
    <content type="html"><![CDATA[<p><a href="http://www.app47.com/">We</a> recently implemented a new feature that required two interesting aspects: storing a file in <a href="http://www.mongodb.org/">MongoDB</a> using <a href="http://docs.mongodb.org/manual/applications/gridfs/">GridFS</a> (think traditional <a href="http://en.wikipedia.org/wiki/Binary_large_object">Blob</a>) and then pushing that file down to a browser. Along the way, I discovered a lot of questions on <a href="http://stackoverflow.com/">stackoverflow</a> and the like pertaining to various aspects of GridFS and <a href="http://www.sinatrarb.com/">Sinatra</a> pushes, so I thought I'd explain what we did.</p>

<p>First off, GridFS is a specification for storing and retrieving large documents. In essence, Mongo breaks a large document into smaller documents (called <em>chunks</em>) and stores them in one collection and associates the meta data related to the aggregated chunks into another collection. It's a fairly handy feature and in our case, it made sense to use <a href="http://docs.mongodb.org/manual/faq/developers/#faq-developers-when-to-use-gridfs">GridFS</a> rather than <a href="http://aws.amazon.com/s3/">S3</a> (or the underlying file system).</p>

<p>All MongoDB drivers implement a similar access pattern to leverage GridFS and they hide the complexity of working with chunks. For example, <a href="https://github.com/mongodb/mongo-ruby-driver">the Ruby driver</a> simply provides a <a href="https://github.com/mongodb/mongo-ruby-driver/wiki/GridFS">single interface to manage the two GridFS collections</a>. In fact, <a href="https://github.com/mongodb/mongo-ruby-driver/blob/master/lib/mongo/gridfs/grid.rb">the interface</a> basically provides two methods: <code>get</code> &amp; <code>put</code> which might seem somewhat limiting, especially because <code>get</code> takes an <code>_id</code>! What's more, you can add rich meta data to a GridFS document (via the <code>put</code> call) -- data you'd conceivably want to query by, but at first glance, you can't via the <code>get</code> method. Nevertheless, because GridFS is ultimately two collections in Mongo, you can query them as you would any other collection.</p>

<p>Thus, finding files by some attribute other than their <code>_id</code> is as easy as writing the corresponding query:</p>

<p><code>ruby GridFS example
file = @mongo['user_apks.files'].find({:filename =&gt; user_id.to_s}).first
</code></p>

<p>Keep in mind, however, that the result returned above is a JSON document -- i.e. the variable <code>file</code> above isn't a pointer to an actual I/O instance but simply a JSON document with its details. To get the actual file, use the <code>get</code> method provided by the driver's GridFS facade -- this'll handle the details of grabbing the file from GridFS. The <code>get</code> method takes an <code>_id</code>, which you can get from the <code>file</code> document. Thus, to get an instance of a readable file, you can grab it like so:</p>

<p><code>ruby get via _id
@grid.get(file['_id'])
</code></p>

<p>Thus, with the <code>get</code> call you can actually get ahold of a file instance and not some JSON document describing it.</p>

<p>To push this instance down to a browser using <a href="http://thediscoblog.com/blog/2012/12/10/sinatra-coffeescript-and-haml-swinging-in-4-steps/">Sinatra</a>, you need to do 3 things:</p>

<ul>
<li>set the content type</li>
<li>set the attachment name</li>
<li>write the file to the response</li>
</ul>


<p>In our case, the file is an <a href="http://developer.android.com/index.html">Android</a> app; accordingly, the content type is <code>application/vnd.android.package-archive</code> and as you'll note, the attachment is simply the name of the <code>.apk</code> file. Finally, the response to the request is written to by <em>reading</em> from the corresponding GridFS file:</p>

<p><code>ruby Sinatra push
get '/some/url/:account_id/:user_id', :agent =&gt; /Android/ do |account_id, user_id|
  file = # get the file from GridFS
  content_type 'application/vnd.android.package-archive'
  attachment "#{file.filename}.apk"
  response.write file.read
end
</code>
As you can see, it's all quite easy -- GridFS is simply a facade for two collections; moreover, forcing a download in Sinatra is three straightforward steps. Can you dig it, man?</p>
]]></content>
  </entry>
  
</feed>
