<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Ruby | The Disco Blog]]></title>
  <link href="http://thediscoblog.com/blog/categories/ruby/atom.xml" rel="self"/>
  <link href="http://thediscoblog.com/"/>
  <updated>2014-04-01T21:18:22-07:00</updated>
  <id>http://thediscoblog.com/</id>
  <author>
    <name><![CDATA[Andrew Glover]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Just require tire to inquire]]></title>
    <link href="http://thediscoblog.com/blog/2013/12/29/just-require-tire-to-inquire/"/>
    <updated>2013-12-29T12:53:00-08:00</updated>
    <id>http://thediscoblog.com/blog/2013/12/29/just-require-tire-to-inquire</id>
    <content type="html"><![CDATA[<p><img class="right" src="/images/mine/es-bonzai.jpg">In the land of <a href="http://thediscoblog.com/blog/categories/ruby/">Ruby</a> there's a few client libraries for <a href="http://thediscoblog.com/blog/categories/elasticsearch/">Elasticsearch</a>, however, one stands above the rest with a comprehensive set of features and remarkable <a href="http://karmi.github.io/retire/">documentation</a>: <a href="https://github.com/karmi/retire">Tire</a>.</p>

<p>With its DSL based API, you'll find working with <a href="http://www.ibm.com/developerworks/library/j-javadev2-24/">Elasticsearch</a> straightforward and a lot of fun. And even though the project's repository has been renamed to <a href="https://github.com/karmi/retire/wiki/Tire-Retire">retire</a>, the Tire library</p>

<p><blockquote><p>will continue to work...bugs will be fixed and important features will be added.</p><footer><strong>Karel Minarik</strong> <cite><a href='https://github.com/karmi/retire/wiki/Tire-Retire'>Tire Retire</a></cite></footer></blockquote></p>

<p>In my opinion, for the time being, Tire is still superior to the <a href="https://github.com/elasticsearch/elasticsearch-ruby">elasticsearch-ruby</a> alternative in terms of features and its elegant DSL.</p>

<!-- more -->


<p></p>

<p>To begin using Tire, grab the gem. For instance, if you're using Bundler, then add the following line to your <code>Gemfile</code>:</p>

<p><code>ruby Adding Tire to a Gemfile
gem 'tire'
</code></p>

<p>After running a <code>bundle install</code>, you'll be able to require Tire.</p>

<p><code>ruby Requiring Tire
require 'tire'
</code></p>

<p>Tire assumes a locally running instance of Elasticsearch; if you wish to connect to a remote node, then create a <code>configure</code> block and set the <code>url</code> to a remote Elasticsearch instance.</p>

<p><code>ruby Configuring a remote Elasticsearch instance
Tire.configure do
  url environment['elasticsearch_host']
end
</code></p>

<p>In the code above, the <code>url</code> is set the value of <code>elasticsearch_host</code>.</p>

<h5>Dealing with Indexes</h5>

<p>First and foremost to working with Elasticsearch is the creation of an index, which can be thought of as a database. Search-able documents are then stored in an index and the process of adding documents to an index is known as <em>indexing</em>.</p>

<p>Consequently, to create an index, you simply name it an issue a <code>create</code> in an <code>index</code> block.</p>

<p><code>ruby Creating an index
Tire.index 'beer_recipes' do
  create
end
</code></p>

<p>In this case, the index is named 'beer_recipes'.</p>

<p>As I've <a href="http://thediscoblog.com/blog/2013/09/14/understanding-elasticsearch-analyzers/">covered before</a>, you can alter how Elasticsearch indexes a document by providing a customized index mapping. In the code below, I've specified that the <code>ingredients</code> property of the <code>beer</code> type will be analyzed using the snowball algorithm, which converts a word into its root, yielding a simpler token (i.e. 'lemons' becomes 'lemon', 'jazzy' becomes 'jazz').</p>

<p>``` ruby Changing the mapping of an index
Tire.index 'beer_recipes' do
  create mappings:  {</p>

<pre><code>beer: {
    properties: { 
        ingredients:  { type: 'string', analyzer: 'snowball' } 
    } 
}
</code></pre>

<p>  }
end
```</p>

<p>Finally, to delete an index, simply issue a <code>delete</code>, like so:</p>

<p>``` ruby Delete an index
Tire.index 'beer_recipes' do</p>

<pre><code>delete
</code></pre>

<p>end
```</p>

<p>Of course, the whole point of <a href="http://thediscoblog.com/blog/2013/05/14/the-democratization-of-search/">Elasticsearch is search</a>! And searching with Tire is super simple; what's more, Tire offers a slick feature of allowing you to define model objects for both indexing and searching (think <a href="https://gist.github.com/karmi/3200212">ActiveRecord</a> integration).</p>

<h5>Indexing &amp; Searching with Tire</h5>

<p>In <a href="http://thediscoblog.com/blog/categories/elasticsearch/">Elasticsearch</a>, an index can be thought of as a database and a <em>type</em> can be thought of as a database table. Accordingly, when you index a document, you give it a type and associate properties, which essentially act like columns.</p>

<p>Indexing a document is executed via the <code>store</code> command. In the code below, a document is stored as a <code>beer</code> type with three properties: <code>name</code>, <code>style</code>, and <code>ingredients</code>. The <code>refresh</code> command updates the index and accordingly makes this newly indexed document available for search.</p>

<p>``` ruby Indexing a document
Tire.index 'beer_recipes' do</p>

<pre><code>store type: 'beer',
name: "Todd Enders' Witbier",
style: "wit, Belgian ale, wheat beer",
ingredients: "4.0 lbs Belgian pils malt, 4.0 lbs raw soft red winter wheat, 0.5 lbs rolled oats, 0.75 oz coriander, freshly ground Zest from two table oranges and two lemons, 1.0 oz 3.1% AA Saaz, 3/4 corn sugar for priming, Hoegaarden strain yeast"
</code></pre>

<p>  refresh
end
```</p>

<p>Consequently, to search for a document in an index, you use the <code>search</code> method, which returns a list of results.</p>

<p>``` ruby Searching for a document
search_res = Tire.search('beer_recipes') do</p>

<pre><code>query do
    term :ingredients, 'lemon'
end
</code></pre>

<p>end</p>

<p>assert_equal 1, search_res.results.size
assert_equal "Todd Enders' Witbier", search_res.results[0].name
```</p>

<p>In the code above, the <code>search</code> block defines a simple query where the <code>ingredients</code> property is searched for the term 'lemon', which yields one result. Note, the resultant list contains maps whose keys are the document's properties (i.e. <code>name</code>, <code>style</code>, and <code>ingredients</code>).</p>

<p>You can use normal Ruby objects for both indexing and searching in Tire. The only requirement is that your model object provide a <code>type</code>, <code>_type</code> or <code>document_type</code> method as well as a <code>to_indexed_json</code> method.</p>

<p>In this case, I've defined a <code>Beer</code> class that includes the two required methods as well as a class method that enables searching the <code>ingredients</code> property.</p>

<p>``` ruby Using a model object
class Beer</p>

<pre><code>attr_reader :name, :style, :ingredients

class &lt;&lt; self
    def search_ingredients_for(ingredient)
        search_res = Tire.search('beer_recipes') do
        query do
            term :ingredients, ingredient
        end
    end
    search_res.results
    end
end

def initialize(attributes={})
    @attributes = attributes
@attributes.each_pair { |name,value| instance_variable_set :"@#{name}", value }
</code></pre>

<p>  end</p>

<p>  def type</p>

<pre><code>  'beer'
</code></pre>

<p>  end</p>

<p>  def to_indexed_json</p>

<pre><code>@attributes.to_json
</code></pre>

<p>  end</p>

<p>end
```</p>

<p>Next, to make use of my <code>Beer</code> model object, I need to configure Tire to use it via the <code>wrapper</code> command. Once that is done, I can use my <code>Beer</code> object to index beers and to search for them.</p>

<p>``` ruby
Tire.configure do</p>

<pre><code>wrapper Beer #forces results to be of type beer!
</code></pre>

<p>end</p>

<p>Tire.index 'beer_recipes' do</p>

<pre><code>store Beer.new type: 'beer',
name: "Todd Enders' Witbier",
style: "wit, Belgian ale, wheat beer",
ingredients: "4.0 lbs Belgian pils malt, 4.0 lbs raw soft red winter wheat, 0.5 lbs rolled oats, 0.75 oz coriander, freshly ground Zest from two table oranges and two lemons, 1.0 oz 3.1% AA Saaz, 3/4 corn sugar for priming, Hoegaarden strain yeast"
</code></pre>

<p>  refresh
end</p>

<p>results = Beer.search_ingredients_for 'lemons'
assert_equal 1, results.size
assert_equal Beer, results[0].class
assert_equal "Todd Enders' Witbier", results[0].name
```</p>

<p>As you can see above, the <code>store</code> method takes a new instantiated <code>Beer</code> instance; what's more, I can use my <code>search_ingredients_for</code> class method to find a corresponding document.</p>

<p>While there are alternate Ruby <a href="http://thediscoblog.com/blog/2013/01/02/scalable-searching-with-elasticsearch/">Elasticsearch</a> libraries available, Tire is by far the richest -- its features along with its DSL make working with <a href="http://www.ibm.com/developerworks/library/j-javadev2-24/">Elasticsearch</a> easy along with fun. So what are you waiting for? Require Tire to inquire!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Lickety-split custom validations in Rails]]></title>
    <link href="http://thediscoblog.com/blog/2013/06/12/lickety-split-custom-validations-in-rails/"/>
    <updated>2013-06-12T13:19:00-07:00</updated>
    <id>http://thediscoblog.com/blog/2013/06/12/lickety-split-custom-validations-in-rails</id>
    <content type="html"><![CDATA[<p>Have a highly specific, yet custom validation for a particular field on one of your <a href="http://thediscoblog.com/blog/categories/rails/">Rails</a> model objects? Don't want to create a <code>ActiveModel::Validator</code> type? Not a problem!</p>

<p>You can just as easily <a href="http://guides.rubyonrails.org/active_record_validations_callbacks.html">create a method</a> that can be invoked as part of the validation process. For example, imagine a field dubbed <code>uri</code> in some model object; this field must begin with a protocol (i.e. http or https). You can create a validation method like so:</p>

<p>``` ruby Custom validator
def uri_should_start_with_protocol
  if !uri.start_with?('http://') &amp;&amp; !uri.start_with?('https://')</p>

<pre><code>errors.add(:uri, 'Web Address should start with http:// or https://')
</code></pre>

<p>  end
end
```
This method resides in your model. You can then register this method as a validation for your model like so:</p>

<p><code>ruby Wiring the validation
validate :uri_should_start_with_protocol
</code></p>

<p>Now if the <code>uri</code> field doesn't contain http or https, <code>model.save</code> will return <code>false</code>. Done!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Backgrounding tasks in Heroku with Delayed Job]]></title>
    <link href="http://thediscoblog.com/blog/2013/06/10/backgrounding-tasks-in-heroku-with-delayed-job/"/>
    <updated>2013-06-10T12:56:00-07:00</updated>
    <id>http://thediscoblog.com/blog/2013/06/10/backgrounding-tasks-in-heroku-with-delayed-job</id>
    <content type="html"><![CDATA[<p><img class="right" src="/images/mine/heroku-logo-light.png">Long running web requests are bad. They create resource contention among other waiting incoming requests; what's more, with HTTP servers like <a href="https://github.com/defunkt/unicorn">Unicorn</a> (which is rapidly becoming the de facto HTTP server for Rails apps running on <a href="https://get.heroku.com/">Heroku</a>), long running requests are summarily terminated after some threshold (for example, 30 seconds) leaving users with a nasty timeout error (and, of course, other users complaining that it takes forever for your site to do anything). Luckily, with frameworks like <a href="https://github.com/collectiveidea/delayed_job">Delayed Job</a>, backgrounding long running tasks <a href="https://devcenter.heroku.com/articles/delayed-job">couldn't be any easier</a>.</p>

<!-- more -->


<p>To leverage Delayed Job in Heroku, you'll need for follow a few steps. In my case, since I'm using <a href="http://mongoid.org/en/mongoid/index.html">Mongoid</a>, I'm going to use an <a href="https://github.com/collectiveidea/delayed_job_mongoid">alternate Active Record Delayed Job tie-in</a> dubbed <code>delayed_job_mongoid</code>. The reason for this <a href="http://guides.rubyonrails.org/">Active Record</a> integration will become obvious once I show you how to actually force a long running task to be asynchronous. Regardless if you are using Mongoid or not, the Active Record integration is identical.</p>

<p>First and foremost, you'll need to add <code>delayed_job_mongoid</code> to your <code>Gemfile</code> (or if you aren't using Mongoid, add <code>delayed_job_active_record</code>).  Delayed Job stores jobs in your database; consequently, after you run <code>bundle install</code>, proceed to update your underlying MongoDB instance with a new index by running:</p>

<p><code>bash Adding an index and new collection to MongoDB
$&gt; script/rails runner 'Delayed::Backend::Mongoid::Job.create_indexes'
</code></p>

<p>Obviously, if you're using a normal RDMBS, your command will be slightly different (i.e. <code>rake db:migrate</code>).</p>

<p>After that step is complete, you'll need to generate a <code>delayed_job</code> script via:</p>

<p><code>bash Generating the Delayed Job script
$&gt; rails generate delayed_job
</code></p>

<p>This script allows to you execute the Delayed Job framework with a number of options. As it turns out, you don't really need this script as Delayed Job hooks into Rake as well; it is via the Rake integration that Heroku will work with Delayed Job.</p>

<p>Now that you've set up 80% of the infrastructure required to support Delayed Job, you next need to background some long running task. This is the fun part and like everything else so far, it couldn't be any easier.</p>

<p>Delayed Job hooks directly into Active Record and thus, you can background some unit of work on a model object by inserting a <code>delay</code> call. For example, in my case, I had a <code>Group</code> model object that when updated under certain circumstances required that <em>all associated</em> users also be updated (wouldn't it be nice if <a href="https://jira.mongodb.org/browse/SERVER-124">MongoDB supported triggers</a>?). As you can imagine, updating hundreds of users is rather time intensive.</p>

<p>Thus, the user update logic was thrown into a special method (dubbed <code>aysnc_update_users</code>) and was then invoked like so:</p>

<p><code>ruby Adding in a delay backgrounds the async_update_users call
group.delay.async_update_users
</code></p>

<p>This call essentially serializes the logic here into a collection called <code>delayed_backend_mongoid_jobs</code> which can then be invoked asynchronously by another process. And therein lies your last few steps.</p>

<p>Heroku has the notion of <a href="https://devcenter.heroku.com/articles/background-jobs-queueing">worker dynos</a>, which are background processors -- think of worker dynos as engines capable of doing what ever you want them to do. In the case of Delayed Job, you want those worker dynos to invoke jobs residing in the <code>delayed_backend_mongoid_jobs</code> collection (which is conceptually a queue).</p>

<p>To configure a worker dyno, you'll need to do 2 things. First, provision one like so:</p>

<p><code>bash Using Heroku CLI to fire up a worker dyno
$&gt; heroku ps:scale worker=1
</code></p>

<p>You'll then need to update your <code>Procfile</code> to include the command the worker dyno should invoke:</p>

<p><code>ruby Updated Procfile command
worker:  bundle exec rake jobs:work
</code></p>

<p>As you can see, the worker dyno in this case is invoking a <a href="http://rake.rubyforge.org/">Rake task</a> (<code>jobs:work</code>) which is asynchronously polling for new jobs in your conceptual queue and invoking them as they are found.</p>

<p>Finally, deploy to Heroku and keep an eye on the queue for jobs -- you can isolate the dyno workers logs via</p>

<p><code>
$&gt; heroku logs -p worker -t
</code></p>

<p>Was that easy or what?</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[The Rails, CloudFront, and Heroku performance hat-trick]]></title>
    <link href="http://thediscoblog.com/blog/2013/05/01/the-rails-cloudfront-and-heroku-performance-hat-trick/"/>
    <updated>2013-05-01T09:10:00-07:00</updated>
    <id>http://thediscoblog.com/blog/2013/05/01/the-rails-cloudfront-and-heroku-performance-hat-trick</id>
    <content type="html"><![CDATA[<p><img class="right" src="/images/mine/hat-trick.png"><a href="http://aws.amazon.com/cloudfront/">Amazon CloudFront</a> is a pay-as-you-go global <a href="http://en.wikipedia.org/wiki/Content_delivery_network">content delivery network</a> (or CDN) that provides high availability and high performance serving of static assets. Basically, it means users have to wait less time to view your web app regardless of their location on the globe.</p>

<p>It's easy to configure a <a href="http://rubyonrails.org/">Rails</a> app to take advantage of CloudFront; what's more, if your Rails app is hosted on <a href="http://www.ibm.com/developerworks/java/library/j-javadev2-21/">Heroku</a>, there's <a href="https://github.com/romanbsd/heroku-deflater">a nifty gem</a>, dubbed heroku-deflater, that'll enable <a href="http://en.wikipedia.org/wiki/HTTP_compression">HTTP compression</a> of static assets (<a href="http://stackoverflow.com/questions/12326191/any-way-to-serve-gzip-assets-from-heroku">other than images</a>).</p>

<p>To get these three entities to play nicely together requires a few simple steps. Let me show you how.</p>

<!--more-->


<p>First, if you want to enable HTTP gzip compression of static assets other than images from a Heroku app, then add the heroku-deflater gem to your <code>Gemfile</code>. This gem doesn't compress images as in some cases, zipping images creates bigger ones!</p>

<p>Once you've run <code>bundle install</code> and deployed your app to Heroku, fire up a terminal and run <a href="http://thediscoblog.com/blog/2013/04/18/curling-for-wget/">cURL</a> to verify that the HTTP response Content-Encoding is gzip like so:</p>

<p><code>bash cURL testing gzip response
curl -i -H "Accept-Encoding: gzip,deflate" http://your.awesome.web.app
</code></p>

<p>You should see in the response this key phrase:</p>

<p><code>bash cURL response
Content-Encoding: gzip
</code></p>

<p>If you do see the Content-Encoding set to gzip, then you are good to go. If, for some reason, you don't see it, check your environment's configuration file (which you will have to edit to get CloudFront working anyway) and verify that the property <code>config.serve_static_assets</code> is set to <code>true</code>.</p>

<p>Next, sign into the AWS Management Console and enable CloudFront if you haven't already. From the CloudFront admin page, create a new distribution via the Create Distribution button on the top left.</p>

<p><img class="center" src="/images/mine/cloudfront_1.png"></p>

<p>Once the create distribution wizard begins, be sure to select Download as your delivery method.</p>

<p><img class="center" src="/images/mine/cloudfront_2.png"></p>

<p>In the next screen, there are some important fields you'll need to fill out, namely: the Origin Source Name and the Viewer Protocol Policy. For the Origin Source Name, you will need to put in your app's URL or the Heroku URL (if you do not map a custom domain name to it). If you web site supports HTTPS, then be sure to set the Viewer Protocol Policy to HTTP and HTTPS.</p>

<p><img class="center" src="/images/mine/cloudfront_3.png"></p>

<p>The only other important setting after these two is the Price Class. It's here where you can set where CloudFront will essentially serve up your content -- the default setting of Use All Edge Locations is most likely what you need.</p>

<p><img class="center" src="/images/mine/cloudfront_5.png"></p>

<p>Finally, click the Create Distribution button -- once you do that, it'll take a bit for things to initialize (basically, the CDN needs to get built and this may take up to 30 minutes).</p>

<p>Now to configure your Rails app, you'll need to open up your target environment's configuration file (i.e. <code>production.rb</code>). The <a href="http://bindle.me/blog/index.php/395/caches-cdns-and-heroku-cedar">two fields</a> you'll want to be sure are properly set are <code>serve_static_assets</code> and <code>static_cache_control</code>. In particular, you are setting the cache control variable to one year. This means that once a static asset, like a JavaScript file is downloaded to the browser, it'll be cached for one year. Don't fret, however, if you think that'll inhibit change -- the file that is ultimately downloaded has a hash attached to it (via the magic of <a href="http://guides.rubyonrails.org/asset_pipeline.html">Rail's Asset Pipeline</a>). Consequently, the file that is cached is something like <code>your_js_file-asdf098203820980a980</code> where that last bit is a hash value that'll change if the file itself changes.</p>

<p><code>ruby production.rb edited to support CDN
config.serve_static_assets = true
config.static_cache_control = 'public, max-age=31536000'
</code></p>

<p>The last change you need to make to your environment file is to set the <code>asset_host</code> to the CloudFront domain that you just created. You can find this in your AWS Management Console -- it'll be a cryptic URL like http://asdjlkj2321.cloudfront.net.</p>

<p><code>ruby production.rb edited to support asset host
config.action_controller.asset_host = 'the domain name from AWS Dashboard'
</code></p>

<p>Commit your changes and deploy your app.</p>

<p>To verify things are kosher, you'll need to give it some time (check the status of your CloudFront CDN -- if it's status is Enabled then you are good to go!). If things are ready, then fire up a browser and go to your app.</p>

<p>In this case, <a href="http://thediscoblog.com/blog/2013/04/15/chromes-console-commands/">I'm using Chrome</a>. Go to JavaScript console and hit the Network tab.</p>

<p><img class="center" src="/images/mine/cloudfront_6.png"></p>

<p>Surf around and you'll note a few things -- one, that the assets like images and JavaScript files are being severed up from your CDN (just look at the URL) and that the size will often say "(from cache)" -- that means the CDN is handling the load rather than <a href="http://www.ibm.com/developerworks/podcast/glover-heroku-110811/">Heroku</a>. You should also note that your web app is probably a bit more snappy!</p>

<p><img class="center" src="/images/mine/cloudfront_7.png"></p>

<p>Check out your Heroku logs and you'll note fewer hits in this case -- dynamic pages are still being loaded, however, static assets are not anymore -- that's the job of your CDN!</p>

<p>CloudFront isn't free; nevertheless, I think you'll find the corresponding cost quite reasonable. Pricing will vary depending on how much content you'll be serving up with CloudFront -- this is a function of how many visitors you have <em>along with</em> how many static assets that are ultimately downloaded to a user's browser. For instance, 500GB of average content will cost you less than $75/month.</p>

<p>CloudFront's pay-as-you-go model makes it extremely affordable to add a nice bit of pep to your app's performance along with using gzip compression and HTTP caching. And hopefully as I've shown you, it's rather easy to do with a Rails app running on Heroku.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Mongoid batch inserts]]></title>
    <link href="http://thediscoblog.com/blog/2013/03/27/mongoid-batch-inserts/"/>
    <updated>2013-03-27T11:34:00-07:00</updated>
    <id>http://thediscoblog.com/blog/2013/03/27/mongoid-batch-inserts</id>
    <content type="html"><![CDATA[<p>In SQL land, all databases support batch inserts. Batch inserts are an effective and efficient mechanism to insert a lot of similar data. That is, instead of issuing x insert statements, you execute 1 insert with x records. This is much more efficient because the insert statement doesn't need to be re-parsed x times, there is only 1 network trip as opposed to x, and in the case of transactions, there is only 1 transaction instead of x. When compared to x inserts, batch inserts are always faster.</p>

<p>As it turns out, <a href="http://www.mongodb.org/">MongoDB</a> supports <a href="http://docs.mongodb.org/manual/applications/create/#bulk-insert-multiple-documents">batch inserts</a>! And just like in SQL land, Mongo's batching feature is much faster at inserting a lot of data in one insert rather than x inserts.</p>

<p>For example, the <a href="https://github.com/mongodb/mongo-ruby-driver">Mongo Ruby driver</a>'s <a href="https://github.com/mongodb/mongo-ruby-driver/blob/master/lib/mongo/collection.rb#L371">insert method takes a collection</a>; thus, you can insert an array of hashes quite efficiently. Even if you are using a <a href="http://mongoid.org/en/mongoid/index.html">ODM like Mongoid</a>, you can still perform batch inserts as all you need to do is get a reference to the model object's underlying collection and then issue an <code>insert</code> with an array of hashes matching the collection's intended document structure.</p>

<p>For instance, to insert a collection of <code>Tag</code> models (each having 3 fields: <code>name</code>, <code>system_tag</code>, and <code>account_id</code>) in one fell swoop I can do the following:</p>

<p><code>ruby Batch inserts with Mongoid model example
tags = ['a', 'bunch', 'of', 'tags'].collect { |tag| {name: tag, system_tag: true, account_id: id} }
Tag.collection.insert tags
</code></p>

<p>In the code above, the <code>insert</code> takes a collection of hashes; what's more, the <code>insert</code> is tied to the <code>tags</code> collection via the <code>Tag.collection</code> call.</p>

<p>Batch inserts are always faster if you have a lot of similar documents -- in our case, we saw a <em>tremendous</em> performance increase when employing batching.</p>
]]></content>
  </entry>
  
</feed>
