<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: DevOps | The Disco Blog]]></title>
  <link href="http://thediscoblog.com/blog/categories/devops/atom.xml" rel="self"/>
  <link href="http://thediscoblog.com/"/>
  <updated>2015-02-09T18:33:23-08:00</updated>
  <id>http://thediscoblog.com/</id>
  <author>
    <name><![CDATA[Andrew Glover]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Global Continuous Delivery talk at E4E]]></title>
    <link href="http://thediscoblog.com/blog/2015/02/09/global-continuous-delivery-talk-at-e4e/"/>
    <updated>2015-02-09T18:28:00-08:00</updated>
    <id>http://thediscoblog.com/blog/2015/02/09/global-continuous-delivery-talk-at-e4e</id>
    <content type="html"><![CDATA[<p>Back in September of last year, <a href="http://www.engineers4engineers.org/speakers#glover">I had the pleasure</a> of giving a talk about Netflix's Continuous Delivery pipelines at <a href="http://www.engineers4engineers.org/">Constant Contact's 2nd annual Engineers4Engineers Conference</a> in Waltham, MA. It's a fabulous conference and definitely worth attending if you're local to the Boston area.</p>

<!-- more -->


<p>My session examines the Netflix Continuous Delivery model and provides insights that you can leverage in your own Continuous Delivery processes.</p>

<p><div class="embed-video-container"><iframe src="http://www.youtube.com/embed/C4klcuIgrRw "></iframe></div></p>

<p></p>


<p>Take a look and see what you think!</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Continuous Integration is a hack!]]></title>
    <link href="http://thediscoblog.com/blog/2014/12/30/continuous-integration-is-a-hack/"/>
    <updated>2014-12-30T15:21:00-08:00</updated>
    <id>http://thediscoblog.com/blog/2014/12/30/continuous-integration-is-a-hack</id>
    <content type="html"><![CDATA[<p><img class="left" src="/images/mine/surprised-little-boy1.jpg">"<a href="http://www.amazon.com/gp/product/0321336380?ie=UTF8&amp;tag=thdibl-20&amp;linkCode=as2&amp;camp=1789&amp;creative=9325&amp;creativeASIN=0321336380">Continuous Integration</a> is a hack!" said my friend <a href="https://twitter.com/benrady">Ben Rady</a> years ago during a discussion on CI hosted by <a href="http://www.stelligent.com/">Stelligent</a>. At the time, I was incredulous! How dare someone question the value of CI, especially when we had just finished writing a book about it! What's more, our book had been nominated for a prestigious <a href="http://en.wikipedia.org/wiki/Jolt_Awards">Jolt award</a>; indeed, <a href="http://www.drdobbs.com/tools/winners-of-the-18th-jolt-product-excelle/207600666?pgno=2">the following day, our CI book won it</a>!</p>

<p>In retrospect, Ben's point was poignant: CI is <em>reactionary</em>. You still have to wait some amount of time to ascertain correctness. That is, CI implicitly relies on a passive process to run a project's build and any corresponding tests. If those tests fail, you are of course, notified. Nevertheless, that notification is somewhat delayed: by the time a CI process runs the tests and reports on their status, you've already moved on to the next task. So much for failing fast!</p>

<!-- more -->


<p>On the other hand, if tests, which are arguably the <a href="http://www.ibm.com/developerworks/views/java/libraryview.jsp?search_by=code+quality:">quintessential proof of valid integration</a>, are run <em>continuously</em>, then there's no wait time to ascertain issues! Ben's stance is really no surprise (especially if you know him) as he went on to play a major role in <a href="https://infinitest.github.io/">Infinitest</a> and co-author <a href="http://www.amazon.com/gp/product/1934356700/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=1934356700&amp;linkCode=as2&amp;tag=thdibl-20&amp;linkId=B53N2UWBWAKQNAVH">Continuous Testing: with Ruby, Rails, and JavaScript</a>. I've come to realize Ben's wisdom since then and have become a huge fan of Continuous Testing.</p>

<iframe style="float: right; margin-left: 1.5em; margin-top: 1.0em; width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="http://thediscoblog.com//ws-na.amazon-adsystem.com/widgets/q?ServiceVersion=20070822&OneJS=1&Operation=GetAdHtml&MarketPlace=US&source=ss&ref=ss_til&ad_type=product_link&tracking_id=thdibl-20&marketplace=amazon&region=US&placement=1934356700&asins=1934356700&linkId=R2TMR5VSJAZVXCTS&show_border=true&link_opens_in_new_window=true">
</iframe>


<p> A more proactive means to ensuring all is kosher with a code base is to continuously run your tests as you work. In fact, an even more superior process would be to run any tests for code that has changed. That is, once a mapping has been established between code under test and a corresponding test, then when that code changes, the quickest, arguably most effective way to ensure that code isn't broken is to run its test(s).</p>

<p>One efficient way to ascertain mapping is to name tests after the code they verify proceeded with a <code>test</code> moniker. For example, an <code>Account</code> object would have its corresponding test called <code>AccountTest</code> (or <code>AccountSpec</code>, etc). Any time the <code>Account</code> object changes, then the <code>AccountTest</code> would be run.</p>

<p><a href="http://www.amazon.com/gp/product/1934356700/ref=as_li_tl?ie=UTF8&amp;camp=1789&amp;creative=390957&amp;creativeASIN=1934356700&amp;linkCode=as2&amp;tag=thdibl-20&amp;linkId=FUVGSKMDG7GWI3CB">Continuous Testing</a> is an established practice in the world of Ruby. A great framework that facilitates it is called <a href="http://www.javaworld.com/article/2074593/core-java/continuous-android-testing-with-guard.html">Guard</a>. Briefly, <a href="https://github.com/guard/guard">Guard</a> is a framework for watching a file system and sending out a notification upon some event (like a change).  With Guard, you can define specific file matching patterns and a corresponding action to take when an event is triggered. You can probably see that this linkage facilitates running tests continuously.</p>

<p>There's really no corollary framework or tool in Java (other than Infinittest and other IDE tools). Nevertheless, you can use Guard to continuously test a <a href="http://thediscoblog.com/blog/categories/java/">Java</a> project. I wrote about <a href="http://www.javaworld.com/article/2074593/core-java/continuous-android-testing-with-guard.html">how to do it with an Android over two years ago</a> and about 6 months ago I got involved in a Guard plugin for Gradle, dubbed <a href="https://github.com/bricker/guard-gradle">Guard::Gradle</a>.</p>

<p>To use Guard::Gradle, you'll need to have <a href="http://thediscoblog.com/blog/categories/ruby/">Ruby</a> installed. For those on <a href="http://thediscoblog.com/blog/categories/osx/">OSX</a>, you already have Ruby. Once you have Ruby installed, the installation of Guard::Gradle couldn't be more easy: just open up a terminal in your desired Gradle project and type:</p>

<p><code>bash Simple installation!
$ curl https://raw.githubusercontent.com/bricker/guard-gradle/master/etc/installer.sh | bash -
</code></p>

<p>The above command will download a script and execute it. That script will:</p>

<ul>
<li>Install Ruby's <a href="http://bundler.io/">Bundler</a></li>
<li>Install the Guard::Gradle plugin</li>
<li>Create a default <code>Guardfile</code></li>
<li>Create a Guard launcher script, dubbed <code>guard.sh</code></li>
</ul>


<p>Therefore, after you run the above command, just execute <code>guard.sh</code> to start Guard::Gradle! Any time you change a file in your source tree, a <a href="http://www.ibm.com/developerworks/java/library/j-cq10316/">corresponding test</a> will be executed using the Gradle <code>test</code> task.</p>

<p>The default <code>Guardfile</code> assumes a standard Gradle project setup, with source code located in <code>src/main</code>. In fact, if you are  curious, take a look at the generated <code>Guardfile</code> and you'll see:</p>

<p><code>ruby Default Guard::Gradle Guardfile
guard :gradle do
  watch(%r{^src/main/(.+)\.*$}) { |m| m[1].split('.')[0].split('/')[-1] }
end
</code></p>

<iframe style="float: left; margin-right: 1.5em; margin-top: 0.7em; margin-bottom: 0.5em; width:120px;height:240px;" marginwidth="0" marginheight="0" scrolling="no" frameborder="0" src="http://thediscoblog.com//ws-na.amazon-adsystem.com/widgets/q?ServiceVersion=20070822&OneJS=1&Operation=GetAdHtml&MarketPlace=US&source=ss&ref=ss_til&ad_type=product_link&tracking_id=thdibl-20&marketplace=amazon&region=US&placement=0321336380&asins=0321336380&linkId=GQYZOKPUZCUVELWX&show_border=true&link_opens_in_new_window=true">
</iframe>


<p>That <code>watch</code> command examines the <code>src/main</code> directory and attempts to execute a matched file's test. If no test is found, all tests are run. So either way, if a change happens, you're <a href="http://www.ibm.com/developerworks/java/library/j-cq01316/index.html">covered with some amount of tests</a>.
which ostensibly updates your local directory with all <a href="http://thediscoblog.com/blog/categories/git/">upstream changes</a>). Consequently, if upstream changes have broken your local branch, you'll know instantly. No more need to remember to "run the tests" -- they're <em>always</em> running.</p>

<p>Of course, Continuous Integration isn't a hack. But Ben made a prescient point back then: if you want to fail fast and shorten the time to detect failures, why not do it at the source? Why not know instantly while you're working instead of some later time after you've moved on? Assuming your <a href="http://thediscoblog.com/blog/categories/tdd/">project has tests</a>, then Continuous Testing is the answer. Continuous Testing is the proactive yin to CI's reactive yang.</p>

<p>Check out <a href="https://github.com/bricker/guard-gradle">Guard:Gradle</a> today and know <em>instantly</em> when you've made a breaking change! Now that's something everyone can dig, right?</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Docker containers with Gradle in 4 steps]]></title>
    <link href="http://thediscoblog.com/blog/2014/06/13/docker-containers-with-gradle-in-4-steps/"/>
    <updated>2014-06-13T11:52:00-07:00</updated>
    <id>http://thediscoblog.com/blog/2014/06/13/docker-containers-with-gradle-in-4-steps</id>
    <content type="html"><![CDATA[<p><img class="right" src="/images/mine/fourdoor.jpg"> Do you need to create a <a href="http://www.docker.com/">Docker</a> image from your Java web app? Are you using <a href="http://www.gradle.org/">Gradle</a>? If so, then you are only 4 steps away from Docker nivana.</p>

<p>For this example, I'm going to use a simple <a href="http://projects.spring.io/spring-boot/">Spring Boot</a> application. You can find all the source code in my <a href="https://github.com/aglover/galoshe">Github repository dubbed galoshe</a>.</p>

<p>If you haven't had a chance to see Spring Boot in action, then you're in for a treat, <em>especially</em> if the words <em>simple</em> and <em>Java web app</em> in the same sentence make you flinch. That was certainly my long standing reaction until I took a serious look at Boot.</p>

<!-- more -->


<p></p>

<p>For instance, a quick and dirty "hello world" Boot app is essentially more imports &amp; annotations than actual code. Check it out:</p>

<p>```java A simple Spring Boot application
package com.github.aglover.galoshe;</p>

<p>import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.EnableAutoConfiguration;
import org.springframework.context.ApplicationContext;
import org.springframework.context.annotation.ComponentScan;
import org.springframework.context.annotation.Configuration;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RestController;</p>

<p>@RestController
@Configuration
@EnableAutoConfiguration
@ComponentScan
public class Application {</p>

<p>  public static void main(String[] args) {</p>

<pre><code>ApplicationContext ctx = SpringApplication.run(Application.class, args);
</code></pre>

<p>  }</p>

<p>  @RequestMapping("/")
  public String index() {</p>

<pre><code>return "Hello to you, world";
</code></pre>

<p>  }
}
```</p>

<p>Running this application is as easy as typing:</p>

<p><code>bash
$ java -jar build/libs/galoshe-0.1.0.jar
</code></p>

<p>That command will fire up an embedded web container with the request path <code>/</code> mapped to return the simple <code>String</code> "Hello to you, world". You can define what port this application will run on via an <code>application.properties</code> file like so:</p>

<p><code>java application.properties
server.port: 8080
</code></p>

<p>Consequently, if I take my browser and point it to localhost:8080, I see the pedestrian, but oh-so-gratifying-when-you-see-it salutation.</p>

<p>Now that you've been introduced to the application I'd like to distribute as a Docker container, let me show you how to do it in 4 easy steps.</p>

<p>Keep in mind, however, that in order to use the gradle-docker plugin I use in this example, you'll need to have Docker installed as the plugin shells out to the <code>docker</code> command.</p>

<h4>Step 1: Apply some plugins</h4>

<p>First and foremost, to Docker-ize your application, you'll need to use two Gradle plugins: <code>docker</code> and <code>application</code>.</p>

<p>The <a href="https://github.com/Transmode/gradle-docker">gradle-docker plugin</a> by <a href="https://github.com/Transmode">Transmode</a> is actually 1 of 2 available plugins for Dockering with Gradle. The <a href="https://github.com/bmuschko/gradle-docker-plugin">other plugin</a> by <a href="https://github.com/bmuschko">Ben Muschko</a> of <a href="http://www.gradleware.com/">Gradleware</a> is a bit more advanced with additional features, however, I find the Transmode plugin the easiest and quickest to get going.</p>

<p>The <code>application</code> plugin is actually included <em>automatically</em> via the <code>spring-boot</code> plugin in my particular example, however, if you aren't using Boot, then you'll need to add the following two plugins to your <code>build.gradle</code> file:</p>

<p><code>java
apply plugin: 'application'
apply plugin: 'docker'
</code></p>

<p>As the <code>docker</code> plugin is a 3rd party plugin, you'll need to tell Gradle how to find it via a <code>dependencies</code> clause.</p>

<p>```java Specifying the classpath for the docker plugin
buildscript {</p>

<pre><code>repositories { mavenCentral() }
dependencies {
    classpath 'se.transmode.gradle:gradle-docker:1.1'
}
</code></pre>

<p>}
<code>``
Now your Gradle script is ready to start Docker-ing. Next up, you'll need to provide some clues so the plugin can create a valid [</code>Dockerfile`]<a href="http://thediscoblog.com/blog/2014/05/05/dockerfiles-in-a-jiffy/">5</a>.</p>

<h4>Step 2: Provide some properties</h4>

<p>The gradle-docker plugin doesn't directly create a Docker container -- it merely creates a <code>Dockerfile</code> and then shells out to the <code>docker</code> command to build an image. Consequently, you need to specify a few properties in your <code>build.gradle</code> file so that the corresponding <code>Dockerfile</code> builds a valid container that automatically runs your application.</p>

<p>You need to provide:</p>

<ul>
<li>The class to run i.e. the class in your application that contains a <code>main</code> method</li>
<li>The target JVM version (default is Java 7)</li>
<li><a href="http://thediscoblog.com/blog/2014/03/25/java-8-s-functional-fomentation/">Optionally</a>, a group id, which feeds into the corresponding Docker tag.</li>
</ul>


<p>Accordingly, my <code>build.gradle</code> defines all three properties like so:</p>

<p><code>java Defining properties for the docker plugin
group = 'aglover'
sourceCompatibility = 1.7
mainClassName = 'com.github.aglover.galoshe.Application'
</code></p>

<p>A few notes about these properties. Firstly, <a href="http://thediscoblog.com/blog/2014/03/25/java-8-s-functional-fomentation/">Java 8</a> isn't <em><a href="https://github.com/Transmode/gradle-docker/pull/9">currently</a></em> available for this plugin. If you don't specify a <code>sourceCompatibility</code>, you'll get Java 7. Next, the <code>group</code> property isn't required; however, it helps in Docker tagging. For example, my project's <code>baseName</code> is dubbed <code>galoshe</code>; consequently, when the plugin creates a Docker image, it'll tag that image with the pattern <code>group/name</code>. So in my case, the corresponding image is tagged <code>aglover/galoshe</code>.</p>

<p>Finally, the <code>mainClassName</code> shouldn't be too surprising - it's the hook into your application. In truth, the plugin will create a script that your resultant Docker image will invoke on startup. That script will essentially call the command:</p>

<p><code>bash
java -classpath your_class_path your_main_class
</code></p>

<p>At this point, you are almost done. Next up, you'll need to specify any <code>Dockerfile</code> instructions.</p>

<h4>Step 3: Specify any required Dockerfile instructions</h4>

<p><code>Dockerfile</code>s contain specialized instructions for the corresponding image they create. There <a href="http://thediscoblog.com/blog/2014/05/05/dockerfiles-in-a-jiffy/">are a few important ones</a>; nevertheless, my Boot app only requires one: <code>port</code>, which is set via the <code>exposePort</code> method of the plugin.</p>

<p>Consequently, to ensure my Docker container exposes port 8080 as defined in my <code>application.properites</code> file, I'll add the following clause to my <code>build.gradle</code> file:</p>

<p>```java Specifying port 8080
distDocker {</p>

<pre><code>exposePort 8080
</code></pre>

<p>}
```</p>

<p>A few other aspects you can muddle with via the plugin are <code>addFile</code> which results in an <code>ADD</code> instruction, <code>runCommand</code>, which results in a <code>RUN</code> instruction, and finally <code>setEnvironment</code>, which creates an <code>ENV</code> instruction.</p>

<p>Now you're done with your Gradle build. All that's left to do is run your build and fire the image up!</p>

<h4>Step 4: Build and run it</h4>

<p>Provided you've configured the gradle-plugin properly, all that's left to do is run your build. In this case, the command is simply <code>distDocker</code>.</p>

<p><code>bash Running my build
$ ./gradlew distDocker
</code></p>

<p>The first time you run this command it'll take a bit as various images will be downloaded. Subsequent runs will be lightning quick though.</p>

<p>After your build completes, your image will be created with the tag I noted earlier. In my case, the tag will be <code>aglover/galoshe</code>, which I can quickly see by running the <code>images</code> command:</p>

<p><code>bash Listing available local Docker images
$ docker images
REPOSITORY          TAG                 IMAGE ID            CREATED             VIRTUAL SIZE
aglover/galoshe     latest              332e163221bc        20 hours ago        1.042 GB
dockerfile/java     latest              f9793c257930        3 weeks ago         1.026 GB
</code></p>

<p>I can subsequently run my image like so:</p>

<p><code>bash Running my container
docker run 332e163221bc
</code></p>

<p>I can naturally go to my browser, hit localhost:8080 and find myself quite satisfied that my image runs a nifty greeting.</p>

<p>Of course, I would need to <a href="https://hub.docker.com/u/aglover/">publish this image</a> for others to use it; nevertheless, as you can see, the gradle-plugin allows me to quickly create Docker containers for Java apps.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Dockerfiles in a jiffy]]></title>
    <link href="http://thediscoblog.com/blog/2014/05/05/dockerfiles-in-a-jiffy/"/>
    <updated>2014-05-05T10:19:00-07:00</updated>
    <id>http://thediscoblog.com/blog/2014/05/05/dockerfiles-in-a-jiffy</id>
    <content type="html"><![CDATA[<p><img class="left" src="/images/mine/docker.png"><a href="https://www.docker.io/">Docker</a> is a lightweight container for applications -- think of a Docker as an app in a box, except that the box in this case isn't an entire VM, but the bare necessities required to run a process. Consequently, you can run many Dockers in a VM. In essence, Docker replaces installation steps for a particular app. Rather than having to execute a series of steps to get, say, <a href="http://thediscoblog.com/blog/categories/mongodb/">MongoDB</a> running, you can simply fire up a Mongo Docker image.</p>

<p>Docker images can be created from a <code>Dockerfile</code>, which is similar to a <code>Vagrantfile</code> or even a build script -- it's a prescription for how to assemble an image. You don't need to have a <code>Dockerfile</code> to create a Docker image, however, creating one makes image creation <em>repeatable</em>. It also provides a means for others to verify an image.</p>

<!-- more -->


<p>There are a few key instructions you should be aware of when creating <code>Dockerfiles</code> -- mainly,  <code>FROM</code>, <code>RUN</code>, <code>EXPOSE</code>, and <code>CMD</code>. To demonstrate how easy this process is, I'm going to create a <code>Dockerfile</code> that runs Amazon's DynamoDB Local.</p>

<h4>DynamoDB Local</h4>

<p><a href="http://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Tools.DynamoDBLocal.html">DynamoDB Local</a> is a simple Java application that emulates <a href="http://aws.amazon.com/dynamodb/">AWS DynamoDB</a>. The benefit of using DynamoDB Local is that you can iterate quickly without using bandwidth against the real DynamoDB and you'll save a few coins in the process.</p>

<p>Running DynamoDB Local isn't terribly difficult; in fact, provided you have <a href="http://thediscoblog.com/blog/categories/java/">Java</a> installed, it's as easy as:</p>

<p><code>bash Firing up DynamoDB Local
$ java -Djava.library.path=./DynamoDBLocal_lib -jar DynamoDBLocal.jar
</code></p>

<p>Of course, if you aren't developing a Java application and don't have Java installed, you would need to, of course, install Java. Then you'd need to download the DynamoDB Local package and install it. And then you'd need to run it.</p>

<p>Alternatively, you could just <code>pull</code> a Docker image, <code>run</code> it, and get back to work.</p>

<h4>Creating a Dockerfile</h4>

<p>Creating a <code>Dockerfile</code> is simple. Fire up your favorite editor and follow along.</p>

<p>The first required element, <code>FROM</code>, indicates the base image or parent from which a docker image is built upon. In many cases, this'll be something like <code>ubuntu</code> or <code>centos</code>, for example.  In the case of an image for DynamoDB Local, I'm going to base it off <em>another image</em> that already has Oracle's <a href="http://thediscoblog.com/blog/2014/03/25/java-8-s-functional-fomentation/">Java 8</a> installed. That image is based upon <a href="http://thediscoblog.com/blog/categories/ubuntu/">Ubuntu</a>. Note, basing your <code>FROM</code> off of another image implies the image is available in an accessible Docker index. You can run your own local or remote indexes or use <a href="https://index.docker.io/">Docker's public index</a>.</p>

<p>Consequently, the first two lines of my <code>Dockerfile</code> are:</p>

<p><code>bash FROM and MAINTAINER elements of a Dockerfile
FROM aglover/java8-pier
MAINTAINER Andy Glover "ajglover@gmail.com"
</code></p>

<p>Have a look at my <a href="https://index.docker.io/u/aglover/java8-pier/">java8-pier project</a> and you'll see its <code>Dockerfile</code> has the line <code>FROM ubuntu</code>. The <code>MAINTAINER</code> line is self evident.</p>

<p>The 2nd most important instruction of a <code>Dockerfile</code> is <code>RUN</code>. Think of <code>RUN</code> as <code>bash</code> commands required to set up your Docker image. In the case of setting up DynamoDB Local, there are a few things I would like done on the image. First and foremost, I'd like to update base aspects of the underlying <a href="http://thediscoblog.com/blog/categories/ubuntu/">Ubuntu</a> OS via an <code>apt-get update</code>. Then I'd like to download the DynamoDB Local archive, however, I'd like to use <code>wget</code>, which isn't available on base Ubuntu installs, however. Consequently, I'll install <code>wget</code> while I'm at it.</p>

<p><code>bash apt-get update and wget install
RUN apt-get update -y
RUN apt-get install wget -y
</code></p>

<p>Next, I'm going to <code>wget</code> the latest version of DynamoDB Local via an AWS URL that points to the latest version (which obviously changes); thus, the <code>-O</code> flag forces the downloaded file to the generic name of <code>dynamo.tar.gz</code> (rather than something like <code>dynamodb_local_2014-04-24.tar.gz</code> where the date can change depending on when AWS releases an update). Finally, after the download completes, the file is moved into a directory dubbed <code>dynamodb_local</code>.</p>

<p><code>bash Downloading the archive
RUN wget http://dynamodb-local.s3-website-us-west-2.amazonaws.com/dynamodb_local_latest -O dynamo.tar.gz
RUN tar xvzf dynamo.tar.gz &amp;&amp; mv dynamodb_local_* dynamodb_local
</code></p>

<p>Docker images, by default, don't expose any ports through the host on which they are running. You must expose desired ports via the <code>EXPOSE</code> command. In my case, DynamoDB Local defaults to port 8000; accordingly, I'll specify in my <code>Dockerfile</code> that I wish this port to be open:</p>

<p><code>bash Exposing port 8000
EXPOSE 8000
</code></p>

<p>Finally, as I wish to run a service via my Docker image, I need to fire it up! DynamoDB Local is simply a Java process that requires, at a minimum, two parameters. If I were to run DynamoDB Local manually, the corresponding command would be:</p>

<p><code>bash The command to run DynamoDB Local
$ java -Djava.library.path=./dynamodb_local/DynamoDBLocal_lib -jar ./dynamodb_local/DynamoDBLocal.jar
</code></p>

<p>Consequently, to execute this command in a <code>Dockerfile</code> I'll need to use the <code>CMD</code> instruction (which is probably the most important instruction for creating Dockers!). This instruction takes an array of values -- logically, just take the corresponding manual command and tokenize it by a space and you've got your <code>CMD</code>:</p>

<p><code>bash The CMD instruction is important if your Docker image runs a service
CMD ["java", "-Djava.library.path=./dynamodb_local/DynamoDBLocal_lib", "-jar", "./dynamodb_local/DynamoDBLocal.jar"]
</code></p>

<p>That's it -- 8 lines and you've got a <code>Dockerfile</code> that'll yield Docker image running DynamoDB Local as a service.</p>

<h4>Creating images from Dockerfiles</h4>

<p>With a <code>Dockerfile</code> I can now create an image via the <code>build</code> command. Thus, in a terminal window, I'll change directories to where I've saved my <code>Dockerfile</code> and run the following:</p>

<p><code>bash Building a Docker image
$ docker build -t aglover/dynamodb-pier .
</code></p>

<p><code>aglover/dynamodb-pier</code> is the desired name of my image. After you run this command, you will see a whole lot of commands executed, including the ones specified in your <code>Dockerfile</code>. Once things finish successfully, you should be able to see the resultant image via the <code>images</code> command.</p>

<p><code>bash Listing Docker images
$ docker images
REPOSITORY              TAG                 IMAGE ID            CREATED             VIRTUAL SIZE
aglover/dynamodb-pier   latest              aa51ccc5dc3f        14 seconds ago      1.089 GB
aglover/java8-pier      latest              cb8436bb816a        4 weeks ago         1.026 GB
base                    latest              b750fe79269d        13 months ago       175.3 MB
base                    ubuntu-12.10        b750fe79269d        13 months ago       175.3 MB
base                    ubuntu-quantal      b750fe79269d        13 months ago       175.3 MB
base                    ubuntu-quantl       b750fe79269d        13 months ago       175.3 MB
</code></p>

<p>I can run my newly minted Docker image via its ID, which, if you look closely in the listing above, is <code>aa51ccc5dc3f</code>.</p>

<p><code>bash Running a Docker image
$ docker run aa51ccc5dc3f
2014-05-05 17:04:14.037:INFO:oejs.Server:jetty-8.1.12.v20130726
2014-05-05 17:04:14.119:INFO:oejs.AbstractConnector:Started SelectChannelConnector@0.0.0.0:8000
</code></p>

<p>Note, by default, Docker will run the image in the foreground; accordingly, you can see things are working via the output coming from the DynamoDB Local instance running.</p>

<p>You can run a Docker image as a daemon via the <code>-d</code> flag:</p>

<p><code>bash Running a Docker image as daemon
$ docker run -d aa51ccc5dc3f
7be2708d94eedaa82432d239659ddb696d66004516174a6e2f79f4ec465eb9fc
</code></p>

<p>You can now see what Docker images are running via the <code>ps</code> command.</p>

<p><code>bash Docker ps lists running images
$ docker ps
CONTAINER ID        IMAGE                          COMMAND                CREATED             STATUS              PORTS               NAMES
7be2708d94ee        aglover/dynamodb-pier:latest   java -Djava.library.   17 seconds ago      Up 16 seconds       8000/tcp            compassionate_bardeen
</code></p>

<p>Finally, you can stop an image via the <code>stop</code> command. You must provide the ID of the image, which you can see via a <code>ps</code>.</p>

<p><code>bash Stopping a Docker image
$ docker stop 7be2708d94ee
</code></p>

<p>Docker has a <a href="http://docs.docker.io/use/workingwithrepository/">public repository</a> can you publish to, provided you have an account. Ultimately, publishing is done via the <code>push</code> command. For example, I've published my DynamoDB Local image via:</p>

<p><code>bash Docker pushing
$ docker push aglover/dynamodb-pier
</code></p>

<p>Once an image has been published, it can correspondingly be downloaded via the <code>pull</code> command:</p>

<p><code>bash Using a Docker image
$ docker pull aglover/dynamodb-pier
</code></p>

<p>Think of <code>pull</code>ing as simply downloading and registering a Docker. To use a 'pull'ed Docker, you must still execute the <code>run</code> command.</p>

<p>Docker makes it super easy to distribute pre-packaged applications -- rather than installing various binaries on different operating systems (like MongoDB on OSX for development and <em>a different</em> MongoDB binary on Ubuntu for production), you can use the <em>same</em> package across environments. <code>Dockerfile</code>s make creating Dockers repeatable. And hopefully I've shown you that crafting a <code>Dockerfile</code> isn't terribly difficult.  Go forth and Docker.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Continuous Delivery for Heroku with Jenkins]]></title>
    <link href="http://thediscoblog.com/blog/2014/01/24/continuous-delivery-for-heroku-with-jenkins/"/>
    <updated>2014-01-24T20:43:00-08:00</updated>
    <id>http://thediscoblog.com/blog/2014/01/24/continuous-delivery-for-heroku-with-jenkins</id>
    <content type="html"><![CDATA[<p><img class="left" src="/images/mine/jenkins.png">A <a href="http://thediscoblog.com/blog/categories/devops/">continuous delivery pipeline</a> that leverages <a href="http://jenkins-ci.org/">Jenkins</a> and targets <a href="http://heroku.com/">Heroku</a> is fairly simple to set up, provided you install the Jenkins Git plugin. With this pipeline, changes to a specific Git branch will result in a Heroku deployment.</p>

<p>For this deployment process to work nicely, you should use at least two Git branches, as you'll want to have one branch targeted for auto-deploys and another that doesn't (as it represents active development).  For example, following the <a href="http://nvie.com/posts/a-successful-git-branching-model/">git-flow</a> convention, those two branches could be named <code>development</code> and <code>master</code>, where changes to <code>master</code> are deployed to Heroku and changes to <code>development</code> aren't. Thus, you will have at least two Jenkins jobs that monitor <em>each</em> of these branches.</p>

<!-- more -->


<p>Naturally, this pipeline process is language agnostic -- <a href="http://thediscoblog.com/blog/categories/node/">Node</a>, <a href="http://thediscoblog.com/blog/categories/ruby/">Ruby</a>, <a href="http://thediscoblog.com/blog/categories/java/">Java</a> -- it doesn't matter what you do during your build as this entire process is choreographed via Git.</p>

<p>When approaching Heroku auto-deployment from Jenkins, <em>don't bother with Heroku's API</em> because it's much easier to use the Git publisher feature of Jenkins to push a branch from your repository to Heroku (which uses Git anyway).</p>

<p>At a high level, you'll need to define a Jenkins job that monitors your <code>master</code> Git branch; if there are changes, this job will run whatever your build needs to do and as a post-build step you can publish that branch to Heroku. It's that easy.</p>

<p>To configure this pipeline, you will need the <a href="https://wiki.jenkins-ci.org/display/JENKINS/Git+Plugin">Git plugin</a>. With the Git plugin installed, create a job and in the Source Code management section, add your source Git repository and then add another repository which is the Heroku remote repository.</p>

<p><img class="center" src="/images/mine/scm-jenkins1.png"></p>

<p>Be sure to give the Heroku repository a name like <code>heroku</code>. This is done by clicking the Advanced button under the Credentials section.</p>

<p>Second, in the Post-build Actions section, you'll configure a Git Publisher.</p>

<p><img class="center" src="/images/mine/git-pub.png"></p>

<p>In this case, the Git repository you are going to publish to will be the Heroku one defined earlier.  Hit the Add Branch button and be sure to indicate the <code>master</code> branch as the Branch to push and the Target remote name should be the name your gave to the remote Heroku repository in the Source Code Management section (i.e. <code>heroku</code>).</p>

<p><img class="center" src="/images/mine/scm-jenkins2.png"></p>

<p>Depending on how you've set up your Build Trigger on your job, when a build completes, Jenkins will push the resultant snapshot to the Heroku repository, <a href="http://stackoverflow.com/questions/16840196/tutorial-on-pushing-to-heroku-via-jenkins/20828183#20828183">resulting in a deployment</a>! Now wasn't that easy, man?</p>
]]></content>
  </entry>
  
</feed>
